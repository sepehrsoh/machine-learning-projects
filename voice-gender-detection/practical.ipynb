{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 519.9 KB\n",
      "x_train.shape :  (2534, 20)\n",
      "x_test.shape :  (634, 20)\n",
      "y_train.shape :  (2534,)\n",
      "y_test.shape :  (634,)\n",
      "Cost after iteration 0: 0.695733\n",
      "Cost after iteration 10: 0.570587\n",
      "Cost after iteration 20: 0.511070\n",
      "Cost after iteration 30: 0.472310\n",
      "Cost after iteration 40: 0.442741\n",
      "Cost after iteration 50: 0.418369\n",
      "Cost after iteration 60: 0.397485\n",
      "Cost after iteration 70: 0.379209\n",
      "Cost after iteration 80: 0.363009\n",
      "Cost after iteration 90: 0.348522\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 92.74447949526814 %.\n",
      "Cost after iteration 0: 0.695733\n",
      "Cost after iteration 10: 0.570587\n",
      "Cost after iteration 20: 0.511070\n",
      "Cost after iteration 30: 0.472310\n",
      "Cost after iteration 40: 0.442741\n",
      "Cost after iteration 50: 0.418369\n",
      "Cost after iteration 60: 0.397485\n",
      "Cost after iteration 70: 0.379209\n",
      "Cost after iteration 80: 0.363009\n",
      "Cost after iteration 90: 0.348522\n",
      "Cost after iteration 100: 0.335479\n",
      "Cost after iteration 110: 0.323672\n",
      "Cost after iteration 120: 0.312932\n",
      "Cost after iteration 130: 0.303120\n",
      "Cost after iteration 140: 0.294122\n",
      "Cost after iteration 150: 0.285840\n",
      "Cost after iteration 160: 0.278192\n",
      "Cost after iteration 170: 0.271109\n",
      "Cost after iteration 180: 0.264530\n",
      "Cost after iteration 190: 0.258403\n",
      "Cost after iteration 200: 0.252683\n",
      "Cost after iteration 210: 0.247332\n",
      "Cost after iteration 220: 0.242314\n",
      "Cost after iteration 230: 0.237600\n",
      "Cost after iteration 240: 0.233163\n",
      "Cost after iteration 250: 0.228979\n",
      "Cost after iteration 260: 0.225027\n",
      "Cost after iteration 270: 0.221289\n",
      "Cost after iteration 280: 0.217748\n",
      "Cost after iteration 290: 0.214388\n",
      "Cost after iteration 300: 0.211197\n",
      "Cost after iteration 310: 0.208161\n",
      "Cost after iteration 320: 0.205270\n",
      "Cost after iteration 330: 0.202515\n",
      "Cost after iteration 340: 0.199884\n",
      "Cost after iteration 350: 0.197371\n",
      "Cost after iteration 360: 0.194968\n",
      "Cost after iteration 370: 0.192667\n",
      "Cost after iteration 380: 0.190462\n",
      "Cost after iteration 390: 0.188348\n",
      "Cost after iteration 400: 0.186319\n",
      "Cost after iteration 410: 0.184369\n",
      "Cost after iteration 420: 0.182495\n",
      "Cost after iteration 430: 0.180692\n",
      "Cost after iteration 440: 0.178956\n",
      "Cost after iteration 450: 0.177284\n",
      "Cost after iteration 460: 0.175671\n",
      "Cost after iteration 470: 0.174116\n",
      "Cost after iteration 480: 0.172614\n",
      "Cost after iteration 490: 0.171164\n",
      "Cost after iteration 500: 0.169762\n",
      "Cost after iteration 510: 0.168407\n",
      "Cost after iteration 520: 0.167095\n",
      "Cost after iteration 530: 0.165826\n",
      "Cost after iteration 540: 0.164596\n",
      "Cost after iteration 550: 0.163404\n",
      "Cost after iteration 560: 0.162249\n",
      "Cost after iteration 570: 0.161129\n",
      "Cost after iteration 580: 0.160041\n",
      "Cost after iteration 590: 0.158986\n",
      "Cost after iteration 600: 0.157960\n",
      "Cost after iteration 610: 0.156964\n",
      "Cost after iteration 620: 0.155996\n",
      "Cost after iteration 630: 0.155054\n",
      "Cost after iteration 640: 0.154138\n",
      "Cost after iteration 650: 0.153246\n",
      "Cost after iteration 660: 0.152378\n",
      "Cost after iteration 670: 0.151533\n",
      "Cost after iteration 680: 0.150710\n",
      "Cost after iteration 690: 0.149907\n",
      "Cost after iteration 700: 0.149125\n",
      "Cost after iteration 710: 0.148362\n",
      "Cost after iteration 720: 0.147618\n",
      "Cost after iteration 730: 0.146892\n",
      "Cost after iteration 740: 0.146184\n",
      "Cost after iteration 750: 0.145492\n",
      "Cost after iteration 760: 0.144816\n",
      "Cost after iteration 770: 0.144156\n",
      "Cost after iteration 780: 0.143511\n",
      "Cost after iteration 790: 0.142881\n",
      "Cost after iteration 800: 0.142264\n",
      "Cost after iteration 810: 0.141662\n",
      "Cost after iteration 820: 0.141072\n",
      "Cost after iteration 830: 0.140496\n",
      "Cost after iteration 840: 0.139931\n",
      "Cost after iteration 850: 0.139379\n",
      "Cost after iteration 860: 0.138838\n",
      "Cost after iteration 870: 0.138309\n",
      "Cost after iteration 880: 0.137790\n",
      "Cost after iteration 890: 0.137282\n",
      "Cost after iteration 900: 0.136784\n",
      "Cost after iteration 910: 0.136296\n",
      "Cost after iteration 920: 0.135818\n",
      "Cost after iteration 930: 0.135349\n",
      "Cost after iteration 940: 0.134889\n",
      "Cost after iteration 950: 0.134438\n",
      "Cost after iteration 960: 0.133995\n",
      "Cost after iteration 970: 0.133561\n",
      "Cost after iteration 980: 0.133135\n",
      "Cost after iteration 990: 0.132717\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 97.94952681388013 %.\n",
      "test accuracy 0.9826498422712934\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Introduction to Gender Voice Recognation with Logistic Regression\n",
    "\n",
    "# Index of Contents\n",
    "\n",
    "* [Read Data and Check Features](#1)\n",
    "* [Adjustment of Label values (male = 1, female = 0)](#2)\n",
    "* [Data Normalization](#3)\n",
    "* [Split Operation for Train and Test Data](#4)\n",
    "* [Matrix creation function for initial weight values](#5)\n",
    "* [Sigmoid function declaration](#6)\n",
    "* [Forward and Backward Propogation](#7)\n",
    "* [Updating Parameters](#8)\n",
    "* [Prediction with Test Data](#9)\n",
    "* [Logistic Regression Implementation](#10)\n",
    "* [Logistic Regression with sklearn](#11)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"input\"))\n",
    "\n",
    "\"\"\"\n",
    "Read Data and Check Features\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_csv(\"voice.csv\")\n",
    "\n",
    "# Get some information about our data\n",
    "data.info()\n",
    "\n",
    "\"\"\"\n",
    "***Adjustment of Label values (male = 1, female = 0***\n",
    "* After getting information about data we'll call male as 1 and female as 0***\n",
    "\"\"\"\n",
    "\n",
    "data.label = [1 if each == \"male\" else 0 for each in data.label]\n",
    "\n",
    "data.info() # now we have label as integer\n",
    "\n",
    "\"\"\"\n",
    "***Data Normalization***\n",
    "\"\"\"\n",
    "\n",
    "y = data.label.values # main results male or female\n",
    "x_data = data.drop([\"label\"], axis = 1) # prediction components\n",
    "\n",
    "x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data)).values # all data evaluated from 1 to 0\n",
    "\n",
    "\"\"\"\n",
    "***Split Operation for Train and Test Data***\n",
    "* Data is splitted for training and testing operations. We'll have %20 of data for test and %80 of data for train after split operation.\n",
    "\"\"\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Data Shapes\n",
    "print(\"x_train.shape : \", x_train.shape)\n",
    "print(\"x_test.shape : \", x_test.shape)\n",
    "print(\"y_train.shape : \", y_train.shape)\n",
    "print(\"y_test.shape : \", y_test.shape)\n",
    "\n",
    "# Transform features to rows (Transpose)\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "\"\"\"\n",
    "***Matrix creation function for initial weight values***\n",
    "\"\"\"\n",
    "\n",
    "def initializeWeightsAndBias(dimension): # according to our data dimension will be 20\n",
    "    w = np.full((dimension, 1), 0.01)\n",
    "    b = 0.0\n",
    "    return w,b\n",
    "\n",
    "\"\"\"\n",
    "***Sigmoid function declaration***\n",
    "\"\"\"\n",
    "\n",
    "def sigmoid(z):\n",
    "    y_head = (1 / (1 + np.exp(-z)))\n",
    "    return y_head\n",
    "\n",
    "\"\"\"\n",
    "***Forward and Backward Propogation***\n",
    "* Get z values from sigmoid function and calculate loss and cost.\n",
    "\"\"\"\n",
    "\n",
    "x_train.shape[1]\n",
    "\n",
    "def forward_backward_propogation(w, b, x_train, y_train):\n",
    "\n",
    "    #forward propogation\n",
    "    z = np.dot(w.T, x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train * np.log(y_head) - (1 - y_train) * np.log(1 - y_head)\n",
    "    cost = (np.sum(loss)) / x_train.shape[1] # x_train.shape[1] is for scaling\n",
    "\n",
    "    #backward propogation\n",
    "    derivative_weight = (np.dot(x_train, ((y_head - y_train).T))) / x_train.shape[1] # x_train.shape[1] is for scaling\n",
    "    derivative_bias = np.sum(y_head - y_train) / x_train.shape[1] # x_train.shape[1] is for scaling\n",
    "    gradients = {\"derivative_weight\" : derivative_weight, \"derivative_bias\" : derivative_bias}\n",
    "\n",
    "    return cost, gradients\n",
    "\n",
    "\"\"\"\n",
    "***Updating parameters***\n",
    "* Our purpose is find to optimum weight and bias values using derivative of these values.\n",
    "\"\"\"\n",
    "\n",
    "def update(w, b, x_train, y_train, learningRate, numberOfIteration):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "\n",
    "    # updating(learning) parameters is number_of_iteration times\n",
    "    for i in range(numberOfIteration):\n",
    "        # make forward and backward propogation and find costs and gradients\n",
    "        cost,gradients = forward_backward_propogation(w, b, x_train, y_train)\n",
    "        cost_list.append(cost)\n",
    "        #lets update\n",
    "        w = w - learningRate * gradients[\"derivative_weight\"]\n",
    "        b = b - learningRate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    # we update(learn) paramters weights and bias\n",
    "    parameters = {\"weight\" : w, \"bias\" : b}\n",
    "    plt.plot(index, cost_list2)\n",
    "    plt.xticks(index, rotation = 'vertical')\n",
    "    plt.xlabel(\"Number of Iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list\n",
    "\n",
    "\"\"\"\n",
    "***Prediction with Test Data***\n",
    "* Prediction using test data which is splitted first.\n",
    "\"\"\"\n",
    "\n",
    "def predict(w,b, x_test):\n",
    "    # x_test is an input for forward propogation\n",
    "    z = sigmoid(np.dot(w.T, x_test) + b)\n",
    "    Y_prediction = np.zeros((1, x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is Male (y_head = 1)\n",
    "    # if z is smaller than 0.5, our prediction is Female (y_head = 0)\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "\n",
    "\"\"\"\n",
    "***Logistic Regression Implementation***\n",
    "\"\"\"\n",
    "\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, learningRate, numberOfIterations):\n",
    "    dimension = x_train.shape[0] # that is 20 (feature count of data)\n",
    "    w,b = initializeWeightsAndBias(dimension)\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learningRate, numberOfIterations)\n",
    "    y_prediction_test = predict(parameters[\"weight\"], parameters[\"bias\"], x_test)\n",
    "    print(\"test accuracy : {} %.\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "\n",
    "#Let's try our model and check costs and prediction results.\n",
    "logistic_regression(x_train, y_train, x_test, y_test, learningRate = 1, numberOfIterations = 100)\n",
    "\n",
    "logistic_regression(x_train, y_train, x_test, y_test, learningRate = 1, numberOfIterations = 1000)\n",
    "\n",
    "\"\"\"As you see above, when the iteration is increased, accuracy increasing too.\n",
    "\n",
    "***Logistic Regression with sklearn***\n",
    "* Logistic Regression Classification can be done with sklearn library. All codes which are written above correspond to the codes below.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train.T, y_train.T)\n",
    "print(\"test accuracy {}\".format(lr.score(x_test.T, y_test.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape :  (2534, 20)\n",
      "x_test.shape :  (634, 20)\n",
      "y_train.shape :  (2534,)\n",
      "y_test.shape :  (634,)\n"
     ]
    }
   ],
   "source": [
    "# Transform features to rows (Transpose)\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "# Data Shapes\n",
    "print(\"x_train.shape : \", x_train.shape)\n",
    "print(\"x_test.shape : \", x_test.shape)\n",
    "print(\"y_train.shape : \", y_train.shape)\n",
    "print(\"y_test.shape : \", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "def training(activation='relu', has_dropout=False, mid_n = 8 ):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape = (x_train.shape[1], ) ))    # train shape is like 1000 X 100\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    if has_dropout:\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(mid_n, activation=activation))\n",
    "    if has_dropout:\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    #compile\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    #fit\n",
    "    history = model.fit(x_train, y_train,validation_split=0.2, epochs=100, batch_size=128)\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def evaluating(model, history):\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss :{:0.4f}'.format(test_score[0]))\n",
    "    print('Test accuracy :{:0.2f}'.format(test_score[1]))\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 32)                672       \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6742 - accuracy: 0.5831 - val_loss: 0.6541 - val_accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6409 - accuracy: 0.7213 - val_loss: 0.6190 - val_accuracy: 0.8817\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6000 - accuracy: 0.8421 - val_loss: 0.5703 - val_accuracy: 0.8067\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5542 - accuracy: 0.8372 - val_loss: 0.5232 - val_accuracy: 0.8698\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5080 - accuracy: 0.8564 - val_loss: 0.4733 - val_accuracy: 0.8501\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4612 - accuracy: 0.8624 - val_loss: 0.4231 - val_accuracy: 0.8994\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4145 - accuracy: 0.8772 - val_loss: 0.3785 - val_accuracy: 0.9073\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3709 - accuracy: 0.8851 - val_loss: 0.3319 - val_accuracy: 0.9132\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3298 - accuracy: 0.8979 - val_loss: 0.2917 - val_accuracy: 0.9389\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2893 - accuracy: 0.9186 - val_loss: 0.2507 - val_accuracy: 0.9428\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9285 - val_loss: 0.2192 - val_accuracy: 0.9507\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2241 - accuracy: 0.9413 - val_loss: 0.1930 - val_accuracy: 0.9606\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2002 - accuracy: 0.9507 - val_loss: 0.1722 - val_accuracy: 0.9586\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1803 - accuracy: 0.9517 - val_loss: 0.1538 - val_accuracy: 0.9586\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.9551 - val_loss: 0.1454 - val_accuracy: 0.9763\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9551 - val_loss: 0.1315 - val_accuracy: 0.9684\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1443 - accuracy: 0.9605 - val_loss: 0.1211 - val_accuracy: 0.9625\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1346 - accuracy: 0.9586 - val_loss: 0.1154 - val_accuracy: 0.9566\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.9605 - val_loss: 0.1087 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1210 - accuracy: 0.9635 - val_loss: 0.1067 - val_accuracy: 0.9704\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1182 - accuracy: 0.9640 - val_loss: 0.0993 - val_accuracy: 0.9665\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1142 - accuracy: 0.9655 - val_loss: 0.0961 - val_accuracy: 0.9645\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1133 - accuracy: 0.9645 - val_loss: 0.0937 - val_accuracy: 0.9684\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1104 - accuracy: 0.9679 - val_loss: 0.0911 - val_accuracy: 0.9665\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1047 - accuracy: 0.9650 - val_loss: 0.0912 - val_accuracy: 0.9625\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1013 - accuracy: 0.9665 - val_loss: 0.0889 - val_accuracy: 0.9665\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.9669 - val_loss: 0.0873 - val_accuracy: 0.9684\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0978 - accuracy: 0.9665 - val_loss: 0.0830 - val_accuracy: 0.9704\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9684 - val_loss: 0.0832 - val_accuracy: 0.9684\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9704 - val_loss: 0.0802 - val_accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0918 - accuracy: 0.9684 - val_loss: 0.0781 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0906 - accuracy: 0.9684 - val_loss: 0.0775 - val_accuracy: 0.9724\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0892 - accuracy: 0.9694 - val_loss: 0.0769 - val_accuracy: 0.9704\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0883 - accuracy: 0.9704 - val_loss: 0.0763 - val_accuracy: 0.9724\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0875 - accuracy: 0.9694 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0875 - accuracy: 0.9699 - val_loss: 0.0757 - val_accuracy: 0.9724\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9719 - val_loss: 0.0737 - val_accuracy: 0.9744\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0864 - accuracy: 0.9714 - val_loss: 0.0712 - val_accuracy: 0.9783\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0840 - accuracy: 0.9724 - val_loss: 0.0721 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0829 - accuracy: 0.9724 - val_loss: 0.0718 - val_accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0824 - accuracy: 0.9719 - val_loss: 0.0707 - val_accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 0.0716 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9724 - val_loss: 0.0716 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0685 - val_accuracy: 0.9783\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9704 - val_loss: 0.0691 - val_accuracy: 0.9803\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0813 - accuracy: 0.9743 - val_loss: 0.0704 - val_accuracy: 0.9744\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0796 - accuracy: 0.9743 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0803 - accuracy: 0.9729 - val_loss: 0.0694 - val_accuracy: 0.9724\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0796 - accuracy: 0.9724 - val_loss: 0.0661 - val_accuracy: 0.9763\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0794 - accuracy: 0.9709 - val_loss: 0.0665 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9719 - val_loss: 0.0659 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0765 - accuracy: 0.9748 - val_loss: 0.0679 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0814 - accuracy: 0.9729 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0809 - accuracy: 0.9714 - val_loss: 0.0631 - val_accuracy: 0.9763\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.9739 - val_loss: 0.0660 - val_accuracy: 0.9744\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0765 - accuracy: 0.9743 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0752 - accuracy: 0.9748 - val_loss: 0.0623 - val_accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 0.0751 - val_accuracy: 0.9684\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.0690 - val_accuracy: 0.9744\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9739 - val_loss: 0.0613 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0773 - accuracy: 0.9753 - val_loss: 0.0626 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0731 - accuracy: 0.9743 - val_loss: 0.0618 - val_accuracy: 0.9842\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9748 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0724 - accuracy: 0.9748 - val_loss: 0.0624 - val_accuracy: 0.9744\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0719 - accuracy: 0.9748 - val_loss: 0.0598 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0716 - accuracy: 0.9753 - val_loss: 0.0606 - val_accuracy: 0.9763\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9768 - val_loss: 0.0588 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0712 - accuracy: 0.9758 - val_loss: 0.0619 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9753 - val_loss: 0.0583 - val_accuracy: 0.9803\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.0621 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.0583 - val_accuracy: 0.9783\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0707 - accuracy: 0.9753 - val_loss: 0.0635 - val_accuracy: 0.9744\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0698 - accuracy: 0.9758 - val_loss: 0.0583 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0684 - accuracy: 0.9773 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0701 - accuracy: 0.9748 - val_loss: 0.0595 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.0611 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.0593 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0688 - accuracy: 0.9788 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0703 - accuracy: 0.9743 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0675 - accuracy: 0.9758 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.0561 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0673 - accuracy: 0.9788 - val_loss: 0.0586 - val_accuracy: 0.9763\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0710 - accuracy: 0.9773 - val_loss: 0.0606 - val_accuracy: 0.9763\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0710 - accuracy: 0.9763 - val_loss: 0.0585 - val_accuracy: 0.9744\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9768 - val_loss: 0.0613 - val_accuracy: 0.9704\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0723 - accuracy: 0.9748 - val_loss: 0.0622 - val_accuracy: 0.9724\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.0573 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0661 - accuracy: 0.9773 - val_loss: 0.0543 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0675 - accuracy: 0.9753 - val_loss: 0.0645 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0671 - accuracy: 0.9778 - val_loss: 0.0542 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0671 - accuracy: 0.9773 - val_loss: 0.0554 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0641 - accuracy: 0.9788 - val_loss: 0.0536 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0651 - accuracy: 0.9773 - val_loss: 0.0564 - val_accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0642 - accuracy: 0.9788 - val_loss: 0.0537 - val_accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9758 - val_loss: 0.0555 - val_accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0640 - accuracy: 0.9788 - val_loss: 0.0523 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9788 - val_loss: 0.0535 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9788 - val_loss: 0.0539 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.0527 - val_accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "#relu\n",
    "model, history = training(activation='relu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :0.0587\n",
      "Test accuracy :0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluating(model, history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 32)                672       \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.8234 - accuracy: 0.4933 - val_loss: 0.7956 - val_accuracy: 0.4872\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.7678 - accuracy: 0.4933 - val_loss: 0.7495 - val_accuracy: 0.4872\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7325 - accuracy: 0.4933 - val_loss: 0.7216 - val_accuracy: 0.4872\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7115 - accuracy: 0.4933 - val_loss: 0.7070 - val_accuracy: 0.4872\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7014 - accuracy: 0.4933 - val_loss: 0.6991 - val_accuracy: 0.4872\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6963 - accuracy: 0.4933 - val_loss: 0.6951 - val_accuracy: 0.4872\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6934 - accuracy: 0.4933 - val_loss: 0.6932 - val_accuracy: 0.4872\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6923 - accuracy: 0.4933 - val_loss: 0.6919 - val_accuracy: 0.4872\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6915 - accuracy: 0.5165 - val_loss: 0.6910 - val_accuracy: 0.6588\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.6872 - val_loss: 0.6903 - val_accuracy: 0.6686\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.6408 - val_loss: 0.6896 - val_accuracy: 0.6548\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6896 - accuracy: 0.6502 - val_loss: 0.6890 - val_accuracy: 0.6746\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6890 - accuracy: 0.6581 - val_loss: 0.6881 - val_accuracy: 0.6647\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6882 - accuracy: 0.7040 - val_loss: 0.6873 - val_accuracy: 0.7160\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6872 - accuracy: 0.7311 - val_loss: 0.6862 - val_accuracy: 0.7219\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6862 - accuracy: 0.7356 - val_loss: 0.6849 - val_accuracy: 0.7673\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6849 - accuracy: 0.7356 - val_loss: 0.6833 - val_accuracy: 0.7239\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6833 - accuracy: 0.7390 - val_loss: 0.6815 - val_accuracy: 0.7732\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6814 - accuracy: 0.8012 - val_loss: 0.6792 - val_accuracy: 0.8304\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6791 - accuracy: 0.8032 - val_loss: 0.6763 - val_accuracy: 0.8225\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.8234 - val_loss: 0.6729 - val_accuracy: 0.8245\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6726 - accuracy: 0.8234 - val_loss: 0.6687 - val_accuracy: 0.8343\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6682 - accuracy: 0.8268 - val_loss: 0.6636 - val_accuracy: 0.8185\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6630 - accuracy: 0.8273 - val_loss: 0.6572 - val_accuracy: 0.8363\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6567 - accuracy: 0.8273 - val_loss: 0.6497 - val_accuracy: 0.8402\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6488 - accuracy: 0.8293 - val_loss: 0.6412 - val_accuracy: 0.8225\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6401 - accuracy: 0.8273 - val_loss: 0.6306 - val_accuracy: 0.8343\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.8303 - val_loss: 0.6186 - val_accuracy: 0.8442\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6180 - accuracy: 0.8283 - val_loss: 0.6054 - val_accuracy: 0.8462\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.8328 - val_loss: 0.5912 - val_accuracy: 0.8442\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5906 - accuracy: 0.8352 - val_loss: 0.5758 - val_accuracy: 0.8481\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5759 - accuracy: 0.8333 - val_loss: 0.5600 - val_accuracy: 0.8481\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5605 - accuracy: 0.8411 - val_loss: 0.5430 - val_accuracy: 0.8580\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5449 - accuracy: 0.8421 - val_loss: 0.5273 - val_accuracy: 0.8521\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5301 - accuracy: 0.8446 - val_loss: 0.5100 - val_accuracy: 0.8580\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8451 - val_loss: 0.4952 - val_accuracy: 0.8521\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5004 - accuracy: 0.8481 - val_loss: 0.4775 - val_accuracy: 0.8580\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4863 - accuracy: 0.8574 - val_loss: 0.4624 - val_accuracy: 0.8619\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4731 - accuracy: 0.8629 - val_loss: 0.4479 - val_accuracy: 0.8639\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4605 - accuracy: 0.8663 - val_loss: 0.4327 - val_accuracy: 0.8797\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4485 - accuracy: 0.8663 - val_loss: 0.4185 - val_accuracy: 0.8856\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.8727 - val_loss: 0.4067 - val_accuracy: 0.8817\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4264 - accuracy: 0.8732 - val_loss: 0.3935 - val_accuracy: 0.8915\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4162 - accuracy: 0.8742 - val_loss: 0.3816 - val_accuracy: 0.8955\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4067 - accuracy: 0.8762 - val_loss: 0.3707 - val_accuracy: 0.9014\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3982 - accuracy: 0.8801 - val_loss: 0.3600 - val_accuracy: 0.9073\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3898 - accuracy: 0.8801 - val_loss: 0.3504 - val_accuracy: 0.9093\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3819 - accuracy: 0.8865 - val_loss: 0.3406 - val_accuracy: 0.9152\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3746 - accuracy: 0.8870 - val_loss: 0.3332 - val_accuracy: 0.9093\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3680 - accuracy: 0.8860 - val_loss: 0.3248 - val_accuracy: 0.9112\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3611 - accuracy: 0.8895 - val_loss: 0.3168 - val_accuracy: 0.9172\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.8905 - val_loss: 0.3104 - val_accuracy: 0.9152\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3492 - accuracy: 0.8910 - val_loss: 0.3031 - val_accuracy: 0.9191\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.8925 - val_loss: 0.2972 - val_accuracy: 0.9152\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3376 - accuracy: 0.8949 - val_loss: 0.2917 - val_accuracy: 0.9152\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3317 - accuracy: 0.8979 - val_loss: 0.2848 - val_accuracy: 0.9211\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3249 - accuracy: 0.8994 - val_loss: 0.2793 - val_accuracy: 0.9191\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3186 - accuracy: 0.8999 - val_loss: 0.2727 - val_accuracy: 0.9211\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3123 - accuracy: 0.9018 - val_loss: 0.2663 - val_accuracy: 0.9211\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3052 - accuracy: 0.9038 - val_loss: 0.2593 - val_accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2974 - accuracy: 0.9053 - val_loss: 0.2524 - val_accuracy: 0.9191\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2885 - accuracy: 0.9073 - val_loss: 0.2443 - val_accuracy: 0.9310\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2792 - accuracy: 0.9107 - val_loss: 0.2355 - val_accuracy: 0.9329\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2689 - accuracy: 0.9142 - val_loss: 0.2263 - val_accuracy: 0.9369\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2580 - accuracy: 0.9216 - val_loss: 0.2163 - val_accuracy: 0.9389\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2466 - accuracy: 0.9240 - val_loss: 0.2059 - val_accuracy: 0.9467\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2352 - accuracy: 0.9299 - val_loss: 0.1967 - val_accuracy: 0.9566\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2234 - accuracy: 0.9364 - val_loss: 0.1899 - val_accuracy: 0.9448\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2152 - accuracy: 0.9393 - val_loss: 0.1803 - val_accuracy: 0.9645\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2035 - accuracy: 0.9423 - val_loss: 0.1712 - val_accuracy: 0.9665\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1945 - accuracy: 0.9507 - val_loss: 0.1643 - val_accuracy: 0.9684\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1868 - accuracy: 0.9531 - val_loss: 0.1584 - val_accuracy: 0.9684\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1795 - accuracy: 0.9556 - val_loss: 0.1529 - val_accuracy: 0.9684\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1726 - accuracy: 0.9586 - val_loss: 0.1485 - val_accuracy: 0.9684\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1672 - accuracy: 0.9586 - val_loss: 0.1437 - val_accuracy: 0.9704\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1625 - accuracy: 0.9610 - val_loss: 0.1412 - val_accuracy: 0.9684\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9605 - val_loss: 0.1376 - val_accuracy: 0.9744\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1532 - accuracy: 0.9630 - val_loss: 0.1323 - val_accuracy: 0.9724\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1495 - accuracy: 0.9640 - val_loss: 0.1294 - val_accuracy: 0.9724\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1459 - accuracy: 0.9630 - val_loss: 0.1275 - val_accuracy: 0.9744\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.9669 - val_loss: 0.1240 - val_accuracy: 0.9724\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1397 - accuracy: 0.9655 - val_loss: 0.1212 - val_accuracy: 0.9724\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9640 - val_loss: 0.1188 - val_accuracy: 0.9724\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9674 - val_loss: 0.1175 - val_accuracy: 0.9744\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1319 - accuracy: 0.9674 - val_loss: 0.1148 - val_accuracy: 0.9724\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1310 - accuracy: 0.9689 - val_loss: 0.1128 - val_accuracy: 0.9744\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1278 - accuracy: 0.9684 - val_loss: 0.1110 - val_accuracy: 0.9763\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1264 - accuracy: 0.9679 - val_loss: 0.1093 - val_accuracy: 0.9763\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 0.9689 - val_loss: 0.1076 - val_accuracy: 0.9744\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1234 - accuracy: 0.9674 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1210 - accuracy: 0.9684 - val_loss: 0.1048 - val_accuracy: 0.9783\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1196 - accuracy: 0.9689 - val_loss: 0.1042 - val_accuracy: 0.9744\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1184 - accuracy: 0.9674 - val_loss: 0.1029 - val_accuracy: 0.9783\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1221 - accuracy: 0.9669 - val_loss: 0.1025 - val_accuracy: 0.9744\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1165 - accuracy: 0.9699 - val_loss: 0.0999 - val_accuracy: 0.9783\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1148 - accuracy: 0.9704 - val_loss: 0.0988 - val_accuracy: 0.9763\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1138 - accuracy: 0.9709 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1128 - accuracy: 0.9714 - val_loss: 0.0974 - val_accuracy: 0.9744\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1125 - accuracy: 0.9704 - val_loss: 0.0959 - val_accuracy: 0.9763\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1115 - accuracy: 0.9709 - val_loss: 0.0951 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "# sigmoid\n",
    "model, history = training(activation='sigmoid')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :0.0990\n",
      "Test accuracy :0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluating(model, history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_92 (Dense)            (None, 32)                672       \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.6903 - accuracy: 0.5609 - val_loss: 0.6385 - val_accuracy: 0.8047\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6166 - accuracy: 0.7869 - val_loss: 0.5698 - val_accuracy: 0.8047\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5584 - accuracy: 0.8219 - val_loss: 0.5151 - val_accuracy: 0.8600\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5087 - accuracy: 0.8481 - val_loss: 0.4648 - val_accuracy: 0.8738\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4663 - accuracy: 0.8559 - val_loss: 0.4167 - val_accuracy: 0.8895\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.4210 - accuracy: 0.8663 - val_loss: 0.3723 - val_accuracy: 0.8955\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3808 - accuracy: 0.8816 - val_loss: 0.3287 - val_accuracy: 0.9152\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.8895 - val_loss: 0.2891 - val_accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3023 - accuracy: 0.9003 - val_loss: 0.2519 - val_accuracy: 0.9250\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2649 - accuracy: 0.9122 - val_loss: 0.2205 - val_accuracy: 0.9507\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2297 - accuracy: 0.9339 - val_loss: 0.1829 - val_accuracy: 0.9586\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1933 - accuracy: 0.9507 - val_loss: 0.1593 - val_accuracy: 0.9724\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1676 - accuracy: 0.9620 - val_loss: 0.1398 - val_accuracy: 0.9763\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1497 - accuracy: 0.9650 - val_loss: 0.1287 - val_accuracy: 0.9763\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1383 - accuracy: 0.9665 - val_loss: 0.1175 - val_accuracy: 0.9803\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1279 - accuracy: 0.9674 - val_loss: 0.1106 - val_accuracy: 0.9724\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1227 - accuracy: 0.9684 - val_loss: 0.1036 - val_accuracy: 0.9744\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9660 - val_loss: 0.1058 - val_accuracy: 0.9763\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1156 - accuracy: 0.9684 - val_loss: 0.1007 - val_accuracy: 0.9783\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1123 - accuracy: 0.9709 - val_loss: 0.1002 - val_accuracy: 0.9763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1080 - accuracy: 0.9684 - val_loss: 0.0913 - val_accuracy: 0.9822\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9724 - val_loss: 0.0921 - val_accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9699 - val_loss: 0.0877 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1009 - accuracy: 0.9704 - val_loss: 0.0863 - val_accuracy: 0.9783\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9734 - val_loss: 0.0865 - val_accuracy: 0.9744\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0991 - accuracy: 0.9729 - val_loss: 0.0841 - val_accuracy: 0.9803\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0974 - accuracy: 0.9729 - val_loss: 0.0830 - val_accuracy: 0.9822\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9734 - val_loss: 0.0826 - val_accuracy: 0.9822\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9729 - val_loss: 0.0818 - val_accuracy: 0.9822\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0959 - accuracy: 0.9729 - val_loss: 0.0811 - val_accuracy: 0.9822\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9719 - val_loss: 0.0806 - val_accuracy: 0.9783\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9719 - val_loss: 0.0806 - val_accuracy: 0.9803\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.0822 - val_accuracy: 0.9783\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.0804 - val_accuracy: 0.9803\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0967 - accuracy: 0.9729 - val_loss: 0.0781 - val_accuracy: 0.9803\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0929 - accuracy: 0.9734 - val_loss: 0.0827 - val_accuracy: 0.9724\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0972 - accuracy: 0.9729 - val_loss: 0.0783 - val_accuracy: 0.9803\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0918 - accuracy: 0.9743 - val_loss: 0.0785 - val_accuracy: 0.9763\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0950 - accuracy: 0.9734 - val_loss: 0.0794 - val_accuracy: 0.9763\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0941 - accuracy: 0.9729 - val_loss: 0.0897 - val_accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0954 - accuracy: 0.9729 - val_loss: 0.0783 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0945 - accuracy: 0.9724 - val_loss: 0.0764 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0945 - accuracy: 0.9704 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.0811 - val_accuracy: 0.9783\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0914 - accuracy: 0.9719 - val_loss: 0.0794 - val_accuracy: 0.9744\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0919 - accuracy: 0.9734 - val_loss: 0.0758 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9743 - val_loss: 0.0750 - val_accuracy: 0.9803\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0907 - accuracy: 0.9748 - val_loss: 0.0750 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0917 - accuracy: 0.9743 - val_loss: 0.0785 - val_accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0994 - accuracy: 0.9734 - val_loss: 0.0874 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.0769 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0912 - accuracy: 0.9734 - val_loss: 0.0744 - val_accuracy: 0.9822\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.9748 - val_loss: 0.0747 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0897 - accuracy: 0.9739 - val_loss: 0.0739 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0893 - accuracy: 0.9763 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0892 - accuracy: 0.9748 - val_loss: 0.0746 - val_accuracy: 0.9803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.0730 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0885 - accuracy: 0.9743 - val_loss: 0.0727 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0880 - accuracy: 0.9758 - val_loss: 0.0735 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0890 - accuracy: 0.9758 - val_loss: 0.0722 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0899 - accuracy: 0.9758 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0914 - accuracy: 0.9729 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0910 - accuracy: 0.9743 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0890 - accuracy: 0.9734 - val_loss: 0.0745 - val_accuracy: 0.9763\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0894 - accuracy: 0.9739 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0897 - accuracy: 0.9734 - val_loss: 0.0714 - val_accuracy: 0.9783\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0883 - accuracy: 0.9753 - val_loss: 0.0792 - val_accuracy: 0.9783\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9743 - val_loss: 0.0755 - val_accuracy: 0.9783\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0885 - accuracy: 0.9748 - val_loss: 0.0730 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.9763 - val_loss: 0.0709 - val_accuracy: 0.9783\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9753 - val_loss: 0.0702 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.9758 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0887 - accuracy: 0.9758 - val_loss: 0.0727 - val_accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - accuracy: 0.9743 - val_loss: 0.0709 - val_accuracy: 0.9803\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0909 - accuracy: 0.9719 - val_loss: 0.0709 - val_accuracy: 0.9803\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - accuracy: 0.9729 - val_loss: 0.0711 - val_accuracy: 0.9783\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0877 - accuracy: 0.9748 - val_loss: 0.0723 - val_accuracy: 0.9763\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0873 - accuracy: 0.9763 - val_loss: 0.0695 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0870 - accuracy: 0.9743 - val_loss: 0.0694 - val_accuracy: 0.9803\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0874 - accuracy: 0.9739 - val_loss: 0.0705 - val_accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.9763 - val_loss: 0.0728 - val_accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0867 - accuracy: 0.9763 - val_loss: 0.0687 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0860 - accuracy: 0.9748 - val_loss: 0.0686 - val_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0872 - accuracy: 0.9739 - val_loss: 0.0683 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9743 - val_loss: 0.0690 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.9773 - val_loss: 0.0695 - val_accuracy: 0.9803\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0851 - accuracy: 0.9773 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0865 - accuracy: 0.9768 - val_loss: 0.0677 - val_accuracy: 0.9803\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0862 - accuracy: 0.9768 - val_loss: 0.0689 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0857 - accuracy: 0.9768 - val_loss: 0.0701 - val_accuracy: 0.9783\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0856 - accuracy: 0.9763 - val_loss: 0.0719 - val_accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0847 - accuracy: 0.9773 - val_loss: 0.0671 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0843 - accuracy: 0.9768 - val_loss: 0.0674 - val_accuracy: 0.9783\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0840 - accuracy: 0.9783 - val_loss: 0.0677 - val_accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0855 - accuracy: 0.9743 - val_loss: 0.0695 - val_accuracy: 0.9783\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 0.9773 - val_loss: 0.0670 - val_accuracy: 0.9783\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0840 - accuracy: 0.9778 - val_loss: 0.0678 - val_accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9783 - val_loss: 0.0688 - val_accuracy: 0.9803\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0887 - accuracy: 0.9748 - val_loss: 0.0677 - val_accuracy: 0.9783\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.9758 - val_loss: 0.0663 - val_accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "# tanh\n",
    "model, history = training(activation='tanh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :0.0715\n",
      "Test accuracy :0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluating(model, history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_96 (Dense)            (None, 32)                672       \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.6976 - accuracy: 0.5012 - val_loss: 0.6787 - val_accuracy: 0.5207\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6718 - accuracy: 0.5797 - val_loss: 0.6535 - val_accuracy: 0.6844\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6439 - accuracy: 0.6714 - val_loss: 0.6116 - val_accuracy: 0.7554\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6041 - accuracy: 0.7311 - val_loss: 0.5692 - val_accuracy: 0.8363\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5671 - accuracy: 0.7721 - val_loss: 0.5125 - val_accuracy: 0.8481\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5167 - accuracy: 0.8012 - val_loss: 0.4583 - val_accuracy: 0.9093\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4723 - accuracy: 0.8283 - val_loss: 0.4019 - val_accuracy: 0.9408\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4249 - accuracy: 0.8545 - val_loss: 0.3428 - val_accuracy: 0.9231\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.8658 - val_loss: 0.2926 - val_accuracy: 0.9428\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3464 - accuracy: 0.8964 - val_loss: 0.2499 - val_accuracy: 0.9487\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3123 - accuracy: 0.9028 - val_loss: 0.2154 - val_accuracy: 0.9467\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2834 - accuracy: 0.9073 - val_loss: 0.1933 - val_accuracy: 0.9389\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2674 - accuracy: 0.9048 - val_loss: 0.1747 - val_accuracy: 0.9428\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2335 - accuracy: 0.9240 - val_loss: 0.1467 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2219 - accuracy: 0.9191 - val_loss: 0.1308 - val_accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2070 - accuracy: 0.9299 - val_loss: 0.1222 - val_accuracy: 0.9665\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1932 - accuracy: 0.9304 - val_loss: 0.1127 - val_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1895 - accuracy: 0.9388 - val_loss: 0.1105 - val_accuracy: 0.9724\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1775 - accuracy: 0.9354 - val_loss: 0.1028 - val_accuracy: 0.9724\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1592 - accuracy: 0.9383 - val_loss: 0.1029 - val_accuracy: 0.9625\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1597 - accuracy: 0.9443 - val_loss: 0.0961 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1629 - accuracy: 0.9324 - val_loss: 0.0888 - val_accuracy: 0.9684\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1536 - accuracy: 0.9447 - val_loss: 0.0845 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1496 - accuracy: 0.9413 - val_loss: 0.0831 - val_accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1388 - accuracy: 0.9497 - val_loss: 0.0789 - val_accuracy: 0.9783\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1460 - accuracy: 0.9443 - val_loss: 0.0796 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1382 - accuracy: 0.9492 - val_loss: 0.0760 - val_accuracy: 0.9763\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1354 - accuracy: 0.9487 - val_loss: 0.0751 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1310 - accuracy: 0.9497 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1350 - accuracy: 0.9477 - val_loss: 0.0718 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1339 - accuracy: 0.9472 - val_loss: 0.0707 - val_accuracy: 0.9783\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1276 - accuracy: 0.9497 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1251 - accuracy: 0.9541 - val_loss: 0.0675 - val_accuracy: 0.9783\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9512 - val_loss: 0.0670 - val_accuracy: 0.9783\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1180 - accuracy: 0.9526 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1212 - accuracy: 0.9497 - val_loss: 0.0712 - val_accuracy: 0.9724\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9517 - val_loss: 0.0628 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1211 - accuracy: 0.9507 - val_loss: 0.0661 - val_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 0.9487 - val_loss: 0.0615 - val_accuracy: 0.9803\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.9462 - val_loss: 0.0622 - val_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1114 - accuracy: 0.9541 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1163 - accuracy: 0.9551 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1062 - accuracy: 0.9546 - val_loss: 0.0632 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1067 - accuracy: 0.9595 - val_loss: 0.0606 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1107 - accuracy: 0.9571 - val_loss: 0.0593 - val_accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9571 - val_loss: 0.0568 - val_accuracy: 0.9862\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9581 - val_loss: 0.0576 - val_accuracy: 0.9842\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9625 - val_loss: 0.0598 - val_accuracy: 0.9803\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1030 - accuracy: 0.9660 - val_loss: 0.0601 - val_accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9665 - val_loss: 0.0600 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1027 - accuracy: 0.9729 - val_loss: 0.0597 - val_accuracy: 0.9842\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9758 - val_loss: 0.0563 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0962 - accuracy: 0.9758 - val_loss: 0.0663 - val_accuracy: 0.9803\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1020 - accuracy: 0.9719 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0979 - accuracy: 0.9768 - val_loss: 0.0525 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.9758 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0956 - accuracy: 0.9748 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0938 - accuracy: 0.9773 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0915 - accuracy: 0.9778 - val_loss: 0.0549 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0936 - accuracy: 0.9743 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.0503 - val_accuracy: 0.9862\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0922 - accuracy: 0.9768 - val_loss: 0.0601 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0898 - accuracy: 0.9763 - val_loss: 0.0503 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0922 - accuracy: 0.9778 - val_loss: 0.0540 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0931 - accuracy: 0.9758 - val_loss: 0.0513 - val_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9788 - val_loss: 0.0594 - val_accuracy: 0.9803\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9793 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9773 - val_loss: 0.0516 - val_accuracy: 0.9842\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0864 - accuracy: 0.9763 - val_loss: 0.0574 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0904 - accuracy: 0.9758 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9798 - val_loss: 0.0512 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0924 - accuracy: 0.9783 - val_loss: 0.0515 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9773 - val_loss: 0.0519 - val_accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9793 - val_loss: 0.0515 - val_accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0867 - accuracy: 0.9798 - val_loss: 0.0462 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0832 - accuracy: 0.9768 - val_loss: 0.0487 - val_accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0812 - accuracy: 0.9773 - val_loss: 0.0480 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0803 - accuracy: 0.9783 - val_loss: 0.0467 - val_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9808 - val_loss: 0.0492 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0792 - accuracy: 0.9808 - val_loss: 0.0454 - val_accuracy: 0.9882\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0910 - accuracy: 0.9768 - val_loss: 0.0521 - val_accuracy: 0.9842\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0830 - accuracy: 0.9798 - val_loss: 0.0500 - val_accuracy: 0.9842\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9803 - val_loss: 0.0439 - val_accuracy: 0.9882\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0777 - accuracy: 0.9803 - val_loss: 0.0475 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0745 - accuracy: 0.9808 - val_loss: 0.0468 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0761 - accuracy: 0.9808 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0788 - accuracy: 0.9793 - val_loss: 0.0503 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 0.0475 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0775 - accuracy: 0.9803 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0780 - accuracy: 0.9783 - val_loss: 0.0487 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9808 - val_loss: 0.0466 - val_accuracy: 0.9862\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.0492 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0777 - accuracy: 0.9813 - val_loss: 0.0466 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 0.9808 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0739 - accuracy: 0.9793 - val_loss: 0.0426 - val_accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0752 - accuracy: 0.9798 - val_loss: 0.0435 - val_accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0795 - accuracy: 0.9798 - val_loss: 0.0481 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0774 - accuracy: 0.9808 - val_loss: 0.0479 - val_accuracy: 0.9842\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0799 - accuracy: 0.9793 - val_loss: 0.0489 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0742 - accuracy: 0.9793 - val_loss: 0.0454 - val_accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "# dropout\n",
    "model, history = training(activation='relu',has_dropout=True )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :0.0646\n",
      "Test accuracy :0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluating(model, history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.6815 - accuracy: 0.5703 - val_loss: 0.6557 - val_accuracy: 0.7673\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6483 - accuracy: 0.7124 - val_loss: 0.6226 - val_accuracy: 0.8166\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6209 - accuracy: 0.7405 - val_loss: 0.5890 - val_accuracy: 0.8323\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5902 - accuracy: 0.7622 - val_loss: 0.5483 - val_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5555 - accuracy: 0.7701 - val_loss: 0.5038 - val_accuracy: 0.8422\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5187 - accuracy: 0.7859 - val_loss: 0.4586 - val_accuracy: 0.8540\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4880 - accuracy: 0.7987 - val_loss: 0.4144 - val_accuracy: 0.8895\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4371 - accuracy: 0.8357 - val_loss: 0.3680 - val_accuracy: 0.9053\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4133 - accuracy: 0.8525 - val_loss: 0.3240 - val_accuracy: 0.9191\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3582 - accuracy: 0.8900 - val_loss: 0.2808 - val_accuracy: 0.9250\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3449 - accuracy: 0.8811 - val_loss: 0.2452 - val_accuracy: 0.9389\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3051 - accuracy: 0.9028 - val_loss: 0.2153 - val_accuracy: 0.9527\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2717 - accuracy: 0.9196 - val_loss: 0.1898 - val_accuracy: 0.9625\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2444 - accuracy: 0.9260 - val_loss: 0.1662 - val_accuracy: 0.9606\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2313 - accuracy: 0.9270 - val_loss: 0.1482 - val_accuracy: 0.9606\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9324 - val_loss: 0.1384 - val_accuracy: 0.9724\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2104 - accuracy: 0.9329 - val_loss: 0.1296 - val_accuracy: 0.9783\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1961 - accuracy: 0.9418 - val_loss: 0.1178 - val_accuracy: 0.9625\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1847 - accuracy: 0.9443 - val_loss: 0.1142 - val_accuracy: 0.9783\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1731 - accuracy: 0.9482 - val_loss: 0.1072 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1781 - accuracy: 0.9477 - val_loss: 0.1020 - val_accuracy: 0.9783\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1592 - accuracy: 0.9502 - val_loss: 0.0977 - val_accuracy: 0.9684\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1628 - accuracy: 0.9526 - val_loss: 0.0948 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1473 - accuracy: 0.9566 - val_loss: 0.0934 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1561 - accuracy: 0.9536 - val_loss: 0.0905 - val_accuracy: 0.9763\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1382 - accuracy: 0.9640 - val_loss: 0.0930 - val_accuracy: 0.9684\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1437 - accuracy: 0.9526 - val_loss: 0.0873 - val_accuracy: 0.9684\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1461 - accuracy: 0.9561 - val_loss: 0.0843 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1343 - accuracy: 0.9581 - val_loss: 0.0840 - val_accuracy: 0.9783\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1292 - accuracy: 0.9650 - val_loss: 0.0809 - val_accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1325 - accuracy: 0.9571 - val_loss: 0.0793 - val_accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1242 - accuracy: 0.9615 - val_loss: 0.0782 - val_accuracy: 0.9783\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1241 - accuracy: 0.9610 - val_loss: 0.0786 - val_accuracy: 0.9822\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1213 - accuracy: 0.9595 - val_loss: 0.0813 - val_accuracy: 0.9704\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9645 - val_loss: 0.0764 - val_accuracy: 0.9783\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1134 - accuracy: 0.9640 - val_loss: 0.0735 - val_accuracy: 0.9783\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.9600 - val_loss: 0.0751 - val_accuracy: 0.9803\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1144 - accuracy: 0.9669 - val_loss: 0.0743 - val_accuracy: 0.9783\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1134 - accuracy: 0.9655 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1127 - accuracy: 0.9665 - val_loss: 0.0736 - val_accuracy: 0.9724\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1170 - accuracy: 0.9595 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1050 - accuracy: 0.9704 - val_loss: 0.0775 - val_accuracy: 0.9704\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1070 - accuracy: 0.9650 - val_loss: 0.0689 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9679 - val_loss: 0.0708 - val_accuracy: 0.9783\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9709 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1043 - accuracy: 0.9660 - val_loss: 0.0684 - val_accuracy: 0.9803\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1059 - accuracy: 0.9699 - val_loss: 0.0667 - val_accuracy: 0.9783\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0958 - accuracy: 0.9704 - val_loss: 0.0709 - val_accuracy: 0.9803\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1054 - accuracy: 0.9714 - val_loss: 0.0684 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1018 - accuracy: 0.9724 - val_loss: 0.0649 - val_accuracy: 0.9803\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0977 - accuracy: 0.9714 - val_loss: 0.0646 - val_accuracy: 0.9822\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0981 - accuracy: 0.9689 - val_loss: 0.0648 - val_accuracy: 0.9803\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1059 - accuracy: 0.9743 - val_loss: 0.0706 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1071 - accuracy: 0.9709 - val_loss: 0.0629 - val_accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1015 - accuracy: 0.9699 - val_loss: 0.0629 - val_accuracy: 0.9803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1042 - accuracy: 0.9719 - val_loss: 0.0654 - val_accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0966 - accuracy: 0.9739 - val_loss: 0.0618 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0899 - accuracy: 0.9734 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0951 - accuracy: 0.9739 - val_loss: 0.0617 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0960 - accuracy: 0.9729 - val_loss: 0.0617 - val_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0947 - accuracy: 0.9714 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0942 - accuracy: 0.9758 - val_loss: 0.0574 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0882 - accuracy: 0.9729 - val_loss: 0.0619 - val_accuracy: 0.9783\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9763 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0904 - accuracy: 0.9763 - val_loss: 0.0591 - val_accuracy: 0.9803\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0872 - accuracy: 0.9783 - val_loss: 0.0584 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9753 - val_loss: 0.0597 - val_accuracy: 0.9803\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9788 - val_loss: 0.0595 - val_accuracy: 0.9803\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0916 - accuracy: 0.9734 - val_loss: 0.0592 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9739 - val_loss: 0.0620 - val_accuracy: 0.9803\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.9763 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9743 - val_loss: 0.0572 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.0626 - val_accuracy: 0.9803\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0895 - accuracy: 0.9758 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0875 - accuracy: 0.9768 - val_loss: 0.0582 - val_accuracy: 0.9803\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.9778 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.9743 - val_loss: 0.0585 - val_accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0828 - accuracy: 0.9763 - val_loss: 0.0560 - val_accuracy: 0.9803\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0840 - accuracy: 0.9763 - val_loss: 0.0594 - val_accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.0679 - val_accuracy: 0.9803\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0874 - accuracy: 0.9753 - val_loss: 0.0579 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0854 - accuracy: 0.9758 - val_loss: 0.0597 - val_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0801 - accuracy: 0.9783 - val_loss: 0.0573 - val_accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0862 - accuracy: 0.9778 - val_loss: 0.0576 - val_accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0831 - accuracy: 0.9808 - val_loss: 0.0564 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0863 - accuracy: 0.9763 - val_loss: 0.0596 - val_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9803 - val_loss: 0.0565 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0751 - accuracy: 0.9788 - val_loss: 0.0612 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0801 - accuracy: 0.9788 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0879 - accuracy: 0.9783 - val_loss: 0.0586 - val_accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9753 - val_loss: 0.0594 - val_accuracy: 0.9803\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0844 - accuracy: 0.9758 - val_loss: 0.0597 - val_accuracy: 0.9803\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0874 - accuracy: 0.9743 - val_loss: 0.0591 - val_accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0771 - accuracy: 0.9788 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0825 - accuracy: 0.9773 - val_loss: 0.0594 - val_accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0721 - accuracy: 0.9788 - val_loss: 0.0554 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0811 - accuracy: 0.9778 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9788 - val_loss: 0.0593 - val_accuracy: 0.9803\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 0.0606 - val_accuracy: 0.9803\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_52 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_53 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.6887 - accuracy: 0.5372 - val_loss: 0.6743 - val_accuracy: 0.5089\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6753 - accuracy: 0.5915 - val_loss: 0.6612 - val_accuracy: 0.6588\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6627 - accuracy: 0.6147 - val_loss: 0.6376 - val_accuracy: 0.6903\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6287 - accuracy: 0.7144 - val_loss: 0.5925 - val_accuracy: 0.8718\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5919 - accuracy: 0.7755 - val_loss: 0.5436 - val_accuracy: 0.8757\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5502 - accuracy: 0.7943 - val_loss: 0.4888 - val_accuracy: 0.8817\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5128 - accuracy: 0.8076 - val_loss: 0.4333 - val_accuracy: 0.8994\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4599 - accuracy: 0.8337 - val_loss: 0.3789 - val_accuracy: 0.9053\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8564 - val_loss: 0.3299 - val_accuracy: 0.9112\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3735 - accuracy: 0.8658 - val_loss: 0.2865 - val_accuracy: 0.9093\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.8762 - val_loss: 0.2458 - val_accuracy: 0.9250\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3099 - accuracy: 0.8929 - val_loss: 0.2129 - val_accuracy: 0.9369\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2849 - accuracy: 0.9038 - val_loss: 0.1765 - val_accuracy: 0.9527\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.9156 - val_loss: 0.1496 - val_accuracy: 0.9704\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2236 - accuracy: 0.9280 - val_loss: 0.1339 - val_accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2128 - accuracy: 0.9334 - val_loss: 0.1284 - val_accuracy: 0.9704\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9403 - val_loss: 0.1085 - val_accuracy: 0.9763\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1828 - accuracy: 0.9438 - val_loss: 0.1018 - val_accuracy: 0.9724\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1644 - accuracy: 0.9556 - val_loss: 0.1016 - val_accuracy: 0.9625\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1638 - accuracy: 0.9507 - val_loss: 0.0937 - val_accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1520 - accuracy: 0.9512 - val_loss: 0.0879 - val_accuracy: 0.9724\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1452 - accuracy: 0.9566 - val_loss: 0.0842 - val_accuracy: 0.9803\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1416 - accuracy: 0.9591 - val_loss: 0.0824 - val_accuracy: 0.9803\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.9556 - val_loss: 0.0795 - val_accuracy: 0.9822\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1360 - accuracy: 0.9586 - val_loss: 0.0811 - val_accuracy: 0.9803\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.9620 - val_loss: 0.0763 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1325 - accuracy: 0.9630 - val_loss: 0.0747 - val_accuracy: 0.9763\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1301 - accuracy: 0.9655 - val_loss: 0.0735 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1252 - accuracy: 0.9655 - val_loss: 0.0790 - val_accuracy: 0.9803\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.9586 - val_loss: 0.0759 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1278 - accuracy: 0.9630 - val_loss: 0.0752 - val_accuracy: 0.9803\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9679 - val_loss: 0.0702 - val_accuracy: 0.9763\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1314 - accuracy: 0.9620 - val_loss: 0.0707 - val_accuracy: 0.9724\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1160 - accuracy: 0.9684 - val_loss: 0.0684 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1167 - accuracy: 0.9674 - val_loss: 0.0652 - val_accuracy: 0.9783\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1207 - accuracy: 0.9689 - val_loss: 0.0668 - val_accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1183 - accuracy: 0.9689 - val_loss: 0.0647 - val_accuracy: 0.9783\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1120 - accuracy: 0.9684 - val_loss: 0.0688 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1132 - accuracy: 0.9714 - val_loss: 0.0632 - val_accuracy: 0.9783\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1174 - accuracy: 0.9674 - val_loss: 0.0634 - val_accuracy: 0.9803\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1098 - accuracy: 0.9714 - val_loss: 0.0607 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1042 - accuracy: 0.9704 - val_loss: 0.0620 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1071 - accuracy: 0.9729 - val_loss: 0.0619 - val_accuracy: 0.9783\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1031 - accuracy: 0.9734 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1080 - accuracy: 0.9709 - val_loss: 0.0602 - val_accuracy: 0.9842\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1028 - accuracy: 0.9729 - val_loss: 0.0578 - val_accuracy: 0.9842\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1076 - accuracy: 0.9694 - val_loss: 0.0575 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0943 - accuracy: 0.9729 - val_loss: 0.0568 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0984 - accuracy: 0.9753 - val_loss: 0.0590 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0998 - accuracy: 0.9719 - val_loss: 0.0638 - val_accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1081 - accuracy: 0.9719 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1053 - accuracy: 0.9704 - val_loss: 0.0570 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1033 - accuracy: 0.9739 - val_loss: 0.0587 - val_accuracy: 0.9842\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1063 - accuracy: 0.9694 - val_loss: 0.0551 - val_accuracy: 0.9842\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9709 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.9739 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0998 - accuracy: 0.9729 - val_loss: 0.0550 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1035 - accuracy: 0.9724 - val_loss: 0.0616 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1009 - accuracy: 0.9684 - val_loss: 0.0595 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0973 - accuracy: 0.9758 - val_loss: 0.0530 - val_accuracy: 0.9862\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0997 - accuracy: 0.9758 - val_loss: 0.0590 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0969 - accuracy: 0.9709 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1025 - accuracy: 0.9724 - val_loss: 0.0504 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0957 - accuracy: 0.9724 - val_loss: 0.0514 - val_accuracy: 0.9882\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0956 - accuracy: 0.9743 - val_loss: 0.0529 - val_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0979 - accuracy: 0.9768 - val_loss: 0.0554 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9753 - val_loss: 0.0520 - val_accuracy: 0.9862\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9729 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0984 - accuracy: 0.9748 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0911 - accuracy: 0.9748 - val_loss: 0.0493 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0947 - accuracy: 0.9748 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0915 - accuracy: 0.9768 - val_loss: 0.0482 - val_accuracy: 0.9882\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0935 - accuracy: 0.9748 - val_loss: 0.0485 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0865 - accuracy: 0.9783 - val_loss: 0.0469 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0874 - accuracy: 0.9758 - val_loss: 0.0457 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0994 - accuracy: 0.9758 - val_loss: 0.0465 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9763 - val_loss: 0.0523 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0908 - accuracy: 0.9773 - val_loss: 0.0471 - val_accuracy: 0.9882\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 0.9763 - val_loss: 0.0460 - val_accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9753 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9788 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9753 - val_loss: 0.0491 - val_accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0902 - accuracy: 0.9758 - val_loss: 0.0479 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0873 - accuracy: 0.9788 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9788 - val_loss: 0.0489 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.9748 - val_loss: 0.0453 - val_accuracy: 0.9882\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0863 - accuracy: 0.9773 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0874 - accuracy: 0.9763 - val_loss: 0.0429 - val_accuracy: 0.9901\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0772 - accuracy: 0.9768 - val_loss: 0.0507 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0925 - accuracy: 0.9743 - val_loss: 0.0559 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0888 - accuracy: 0.9783 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0862 - accuracy: 0.9778 - val_loss: 0.0588 - val_accuracy: 0.9803\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0807 - accuracy: 0.9763 - val_loss: 0.0462 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.9793 - val_loss: 0.0445 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0834 - accuracy: 0.9763 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 0.9788 - val_loss: 0.0452 - val_accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0801 - accuracy: 0.9778 - val_loss: 0.0452 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0822 - accuracy: 0.9773 - val_loss: 0.0436 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 0.0458 - val_accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0943 - accuracy: 0.9753 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_54 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.6753 - accuracy: 0.5604 - val_loss: 0.6592 - val_accuracy: 0.6272\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6514 - accuracy: 0.6305 - val_loss: 0.6176 - val_accuracy: 0.7101\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6175 - accuracy: 0.6912 - val_loss: 0.5781 - val_accuracy: 0.7771\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5851 - accuracy: 0.7257 - val_loss: 0.5342 - val_accuracy: 0.7929\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5516 - accuracy: 0.7504 - val_loss: 0.4931 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5110 - accuracy: 0.7810 - val_loss: 0.4490 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4727 - accuracy: 0.8076 - val_loss: 0.4031 - val_accuracy: 0.8757\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4355 - accuracy: 0.8313 - val_loss: 0.3600 - val_accuracy: 0.8915\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4013 - accuracy: 0.8367 - val_loss: 0.3224 - val_accuracy: 0.9073\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3770 - accuracy: 0.8550 - val_loss: 0.2879 - val_accuracy: 0.9172\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3606 - accuracy: 0.8688 - val_loss: 0.2632 - val_accuracy: 0.9349\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3272 - accuracy: 0.8910 - val_loss: 0.2302 - val_accuracy: 0.9349\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3068 - accuracy: 0.8984 - val_loss: 0.2060 - val_accuracy: 0.9586\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2776 - accuracy: 0.9147 - val_loss: 0.1873 - val_accuracy: 0.9684\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2616 - accuracy: 0.9191 - val_loss: 0.1655 - val_accuracy: 0.9546\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2548 - accuracy: 0.9171 - val_loss: 0.1513 - val_accuracy: 0.9665\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2308 - accuracy: 0.9299 - val_loss: 0.1397 - val_accuracy: 0.9586\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2167 - accuracy: 0.9378 - val_loss: 0.1222 - val_accuracy: 0.9684\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2084 - accuracy: 0.9334 - val_loss: 0.1168 - val_accuracy: 0.9783\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1863 - accuracy: 0.9433 - val_loss: 0.1058 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1781 - accuracy: 0.9438 - val_loss: 0.1063 - val_accuracy: 0.9803\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1711 - accuracy: 0.9472 - val_loss: 0.0916 - val_accuracy: 0.9803\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1645 - accuracy: 0.9517 - val_loss: 0.0911 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1640 - accuracy: 0.9556 - val_loss: 0.0842 - val_accuracy: 0.9783\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1440 - accuracy: 0.9610 - val_loss: 0.0793 - val_accuracy: 0.9744\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1491 - accuracy: 0.9512 - val_loss: 0.0834 - val_accuracy: 0.9842\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1450 - accuracy: 0.9600 - val_loss: 0.0747 - val_accuracy: 0.9783\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1420 - accuracy: 0.9615 - val_loss: 0.0737 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1411 - accuracy: 0.9600 - val_loss: 0.0721 - val_accuracy: 0.9783\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1293 - accuracy: 0.9679 - val_loss: 0.0744 - val_accuracy: 0.9783\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1354 - accuracy: 0.9665 - val_loss: 0.0713 - val_accuracy: 0.9783\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1230 - accuracy: 0.9674 - val_loss: 0.0657 - val_accuracy: 0.9803\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1268 - accuracy: 0.9610 - val_loss: 0.0649 - val_accuracy: 0.9803\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1310 - accuracy: 0.9650 - val_loss: 0.0664 - val_accuracy: 0.9763\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1218 - accuracy: 0.9645 - val_loss: 0.0659 - val_accuracy: 0.9803\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1212 - accuracy: 0.9665 - val_loss: 0.0625 - val_accuracy: 0.9842\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 0.9635 - val_loss: 0.0632 - val_accuracy: 0.9763\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9689 - val_loss: 0.0646 - val_accuracy: 0.9783\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9719 - val_loss: 0.0599 - val_accuracy: 0.9803\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1105 - accuracy: 0.9704 - val_loss: 0.0651 - val_accuracy: 0.9803\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9660 - val_loss: 0.0618 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.9630 - val_loss: 0.0600 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9689 - val_loss: 0.0598 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1050 - accuracy: 0.9734 - val_loss: 0.0573 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1029 - accuracy: 0.9704 - val_loss: 0.0591 - val_accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0998 - accuracy: 0.9704 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1127 - accuracy: 0.9709 - val_loss: 0.0584 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9753 - val_loss: 0.0618 - val_accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0981 - accuracy: 0.9719 - val_loss: 0.0583 - val_accuracy: 0.9803\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.9729 - val_loss: 0.0565 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9694 - val_loss: 0.0570 - val_accuracy: 0.9803\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9694 - val_loss: 0.0744 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9689 - val_loss: 0.0559 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0982 - accuracy: 0.9714 - val_loss: 0.0577 - val_accuracy: 0.9783\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9719 - val_loss: 0.0535 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0927 - accuracy: 0.9763 - val_loss: 0.0547 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9724 - val_loss: 0.0541 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0953 - accuracy: 0.9734 - val_loss: 0.0570 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0888 - accuracy: 0.9758 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0975 - accuracy: 0.9758 - val_loss: 0.0533 - val_accuracy: 0.9842\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0866 - accuracy: 0.9773 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0987 - accuracy: 0.9719 - val_loss: 0.0530 - val_accuracy: 0.9842\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9709 - val_loss: 0.0538 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0913 - accuracy: 0.9709 - val_loss: 0.0560 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0899 - accuracy: 0.9753 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0793 - accuracy: 0.9783 - val_loss: 0.0567 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0853 - accuracy: 0.9768 - val_loss: 0.0589 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0935 - accuracy: 0.9729 - val_loss: 0.0516 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0858 - accuracy: 0.9778 - val_loss: 0.0523 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9709 - val_loss: 0.0539 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9694 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9763 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9783 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0900 - accuracy: 0.9743 - val_loss: 0.0515 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.0498 - val_accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0862 - accuracy: 0.9724 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0883 - accuracy: 0.9793 - val_loss: 0.0548 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0780 - accuracy: 0.9783 - val_loss: 0.0501 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 0.0527 - val_accuracy: 0.9842\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0807 - accuracy: 0.9783 - val_loss: 0.0495 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0521 - val_accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0803 - accuracy: 0.9758 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0857 - accuracy: 0.9743 - val_loss: 0.0528 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9763 - val_loss: 0.0518 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9778 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0807 - accuracy: 0.9793 - val_loss: 0.0506 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0844 - accuracy: 0.9788 - val_loss: 0.0529 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.0565 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0789 - accuracy: 0.9798 - val_loss: 0.0492 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0834 - accuracy: 0.9758 - val_loss: 0.0509 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0864 - accuracy: 0.9729 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9753 - val_loss: 0.0519 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.0497 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0848 - accuracy: 0.9739 - val_loss: 0.0605 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9753 - val_loss: 0.0582 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0807 - accuracy: 0.9753 - val_loss: 0.0487 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0781 - accuracy: 0.9803 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 0.0532 - val_accuracy: 0.9842\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 26ms/step - loss: 0.6994 - accuracy: 0.5002 - val_loss: 0.6844 - val_accuracy: 0.4852\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6752 - accuracy: 0.5876 - val_loss: 0.6611 - val_accuracy: 0.6864\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6547 - accuracy: 0.6774 - val_loss: 0.6302 - val_accuracy: 0.7811\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6300 - accuracy: 0.7173 - val_loss: 0.5991 - val_accuracy: 0.8047\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6057 - accuracy: 0.7563 - val_loss: 0.5617 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5727 - accuracy: 0.7637 - val_loss: 0.5230 - val_accuracy: 0.8836\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5387 - accuracy: 0.7928 - val_loss: 0.4755 - val_accuracy: 0.8836\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5110 - accuracy: 0.7997 - val_loss: 0.4380 - val_accuracy: 0.8974\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4666 - accuracy: 0.8298 - val_loss: 0.3889 - val_accuracy: 0.9073\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4269 - accuracy: 0.8451 - val_loss: 0.3422 - val_accuracy: 0.9132\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3948 - accuracy: 0.8559 - val_loss: 0.3016 - val_accuracy: 0.9487\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3565 - accuracy: 0.8781 - val_loss: 0.2589 - val_accuracy: 0.9566\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3170 - accuracy: 0.8885 - val_loss: 0.2319 - val_accuracy: 0.9704\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3012 - accuracy: 0.9028 - val_loss: 0.1931 - val_accuracy: 0.9606\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2685 - accuracy: 0.9235 - val_loss: 0.1687 - val_accuracy: 0.9665\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2395 - accuracy: 0.9275 - val_loss: 0.1493 - val_accuracy: 0.9783\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2283 - accuracy: 0.9299 - val_loss: 0.1346 - val_accuracy: 0.9684\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2063 - accuracy: 0.9354 - val_loss: 0.1205 - val_accuracy: 0.9744\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1965 - accuracy: 0.9477 - val_loss: 0.1117 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1948 - accuracy: 0.9373 - val_loss: 0.1082 - val_accuracy: 0.9783\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1780 - accuracy: 0.9452 - val_loss: 0.1007 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1713 - accuracy: 0.9477 - val_loss: 0.0950 - val_accuracy: 0.9744\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1627 - accuracy: 0.9507 - val_loss: 0.0937 - val_accuracy: 0.9684\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1564 - accuracy: 0.9576 - val_loss: 0.0902 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1622 - accuracy: 0.9556 - val_loss: 0.0851 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1498 - accuracy: 0.9561 - val_loss: 0.0835 - val_accuracy: 0.9763\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1477 - accuracy: 0.9531 - val_loss: 0.0807 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1490 - accuracy: 0.9566 - val_loss: 0.0795 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.0775 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.9615 - val_loss: 0.0781 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9645 - val_loss: 0.0763 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9615 - val_loss: 0.0765 - val_accuracy: 0.9822\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1307 - accuracy: 0.9600 - val_loss: 0.0736 - val_accuracy: 0.9724\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.9660 - val_loss: 0.0730 - val_accuracy: 0.9724\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1269 - accuracy: 0.9650 - val_loss: 0.0727 - val_accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1288 - accuracy: 0.9669 - val_loss: 0.0708 - val_accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1230 - accuracy: 0.9650 - val_loss: 0.0777 - val_accuracy: 0.9704\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1177 - accuracy: 0.9694 - val_loss: 0.0698 - val_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1212 - accuracy: 0.9699 - val_loss: 0.0690 - val_accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1202 - accuracy: 0.9665 - val_loss: 0.0689 - val_accuracy: 0.9724\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1218 - accuracy: 0.9699 - val_loss: 0.0674 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9699 - val_loss: 0.0715 - val_accuracy: 0.9744\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1140 - accuracy: 0.9679 - val_loss: 0.0683 - val_accuracy: 0.9763\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1119 - accuracy: 0.9684 - val_loss: 0.0667 - val_accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1169 - accuracy: 0.9694 - val_loss: 0.0652 - val_accuracy: 0.9724\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1107 - accuracy: 0.9694 - val_loss: 0.0679 - val_accuracy: 0.9763\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1165 - accuracy: 0.9694 - val_loss: 0.0691 - val_accuracy: 0.9744\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1053 - accuracy: 0.9719 - val_loss: 0.0640 - val_accuracy: 0.9763\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1181 - accuracy: 0.9689 - val_loss: 0.0665 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1114 - accuracy: 0.9694 - val_loss: 0.0635 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1088 - accuracy: 0.9689 - val_loss: 0.0658 - val_accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1029 - accuracy: 0.9724 - val_loss: 0.0626 - val_accuracy: 0.9783\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.0619 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1046 - accuracy: 0.9753 - val_loss: 0.0627 - val_accuracy: 0.9763\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1114 - accuracy: 0.9669 - val_loss: 0.0614 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1049 - accuracy: 0.9729 - val_loss: 0.0646 - val_accuracy: 0.9763\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0999 - accuracy: 0.9748 - val_loss: 0.0596 - val_accuracy: 0.9803\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1003 - accuracy: 0.9739 - val_loss: 0.0606 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1104 - accuracy: 0.9699 - val_loss: 0.0595 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1047 - accuracy: 0.9734 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9739 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.9704 - val_loss: 0.0602 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1008 - accuracy: 0.9758 - val_loss: 0.0625 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9719 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1013 - accuracy: 0.9729 - val_loss: 0.0654 - val_accuracy: 0.9783\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - accuracy: 0.9704 - val_loss: 0.0628 - val_accuracy: 0.9763\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1007 - accuracy: 0.9739 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0996 - accuracy: 0.9758 - val_loss: 0.0590 - val_accuracy: 0.9803\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0996 - accuracy: 0.9734 - val_loss: 0.0565 - val_accuracy: 0.9783\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0983 - accuracy: 0.9709 - val_loss: 0.0570 - val_accuracy: 0.9803\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0939 - accuracy: 0.9748 - val_loss: 0.0576 - val_accuracy: 0.9783\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0978 - accuracy: 0.9778 - val_loss: 0.0571 - val_accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0979 - accuracy: 0.9739 - val_loss: 0.0577 - val_accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.9768 - val_loss: 0.0567 - val_accuracy: 0.9783\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0858 - accuracy: 0.9768 - val_loss: 0.0567 - val_accuracy: 0.9783\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9768 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0935 - accuracy: 0.9773 - val_loss: 0.0581 - val_accuracy: 0.9783\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0905 - accuracy: 0.9778 - val_loss: 0.0564 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0960 - accuracy: 0.9729 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0988 - accuracy: 0.9719 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0972 - accuracy: 0.9714 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0951 - accuracy: 0.9748 - val_loss: 0.0550 - val_accuracy: 0.9842\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 0.9719 - val_loss: 0.0581 - val_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0942 - accuracy: 0.9768 - val_loss: 0.0556 - val_accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9729 - val_loss: 0.0558 - val_accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.0624 - val_accuracy: 0.9803\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0959 - accuracy: 0.9719 - val_loss: 0.0571 - val_accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0929 - accuracy: 0.9773 - val_loss: 0.0543 - val_accuracy: 0.9803\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0905 - accuracy: 0.9753 - val_loss: 0.0545 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0937 - accuracy: 0.9748 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0918 - accuracy: 0.9753 - val_loss: 0.0533 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0866 - accuracy: 0.9783 - val_loss: 0.0522 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0928 - accuracy: 0.9763 - val_loss: 0.0619 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0899 - accuracy: 0.9758 - val_loss: 0.0573 - val_accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0912 - accuracy: 0.9734 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0909 - accuracy: 0.9768 - val_loss: 0.0529 - val_accuracy: 0.9803\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0898 - accuracy: 0.9743 - val_loss: 0.0539 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0859 - accuracy: 0.9793 - val_loss: 0.0520 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0872 - accuracy: 0.9803 - val_loss: 0.0530 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0879 - accuracy: 0.9773 - val_loss: 0.0541 - val_accuracy: 0.9783\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 26ms/step - loss: 0.6946 - accuracy: 0.5422 - val_loss: 0.6651 - val_accuracy: 0.7633\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6613 - accuracy: 0.6251 - val_loss: 0.6380 - val_accuracy: 0.7811\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6436 - accuracy: 0.6482 - val_loss: 0.6079 - val_accuracy: 0.8264\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6034 - accuracy: 0.7124 - val_loss: 0.5689 - val_accuracy: 0.8264\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5711 - accuracy: 0.7405 - val_loss: 0.5250 - val_accuracy: 0.8363\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5424 - accuracy: 0.7622 - val_loss: 0.4846 - val_accuracy: 0.8462\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5094 - accuracy: 0.7696 - val_loss: 0.4492 - val_accuracy: 0.8462\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4715 - accuracy: 0.7997 - val_loss: 0.4019 - val_accuracy: 0.8718\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4492 - accuracy: 0.8061 - val_loss: 0.3655 - val_accuracy: 0.8738\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3954 - accuracy: 0.8461 - val_loss: 0.3160 - val_accuracy: 0.9034\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3691 - accuracy: 0.8520 - val_loss: 0.2713 - val_accuracy: 0.9112\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3380 - accuracy: 0.8678 - val_loss: 0.2416 - val_accuracy: 0.9132\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8826 - val_loss: 0.1989 - val_accuracy: 0.9408\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2807 - accuracy: 0.9023 - val_loss: 0.1710 - val_accuracy: 0.9507\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2556 - accuracy: 0.9161 - val_loss: 0.1512 - val_accuracy: 0.9527\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2235 - accuracy: 0.9255 - val_loss: 0.1291 - val_accuracy: 0.9566\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2134 - accuracy: 0.9285 - val_loss: 0.1179 - val_accuracy: 0.9546\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1871 - accuracy: 0.9472 - val_loss: 0.1077 - val_accuracy: 0.9606\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1689 - accuracy: 0.9472 - val_loss: 0.0960 - val_accuracy: 0.9744\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1559 - accuracy: 0.9526 - val_loss: 0.0897 - val_accuracy: 0.9704\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 0.9541 - val_loss: 0.0888 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1592 - accuracy: 0.9556 - val_loss: 0.0855 - val_accuracy: 0.9763\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1430 - accuracy: 0.9571 - val_loss: 0.0834 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1377 - accuracy: 0.9605 - val_loss: 0.0833 - val_accuracy: 0.9783\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1375 - accuracy: 0.9605 - val_loss: 0.0737 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1320 - accuracy: 0.9620 - val_loss: 0.0792 - val_accuracy: 0.9763\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.9625 - val_loss: 0.0764 - val_accuracy: 0.9744\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1293 - accuracy: 0.9605 - val_loss: 0.0709 - val_accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.9625 - val_loss: 0.0726 - val_accuracy: 0.9763\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1185 - accuracy: 0.9615 - val_loss: 0.0672 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1147 - accuracy: 0.9669 - val_loss: 0.0669 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1135 - accuracy: 0.9694 - val_loss: 0.0661 - val_accuracy: 0.9724\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1176 - accuracy: 0.9635 - val_loss: 0.0665 - val_accuracy: 0.9724\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9669 - val_loss: 0.0660 - val_accuracy: 0.9724\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1099 - accuracy: 0.9645 - val_loss: 0.0661 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1116 - accuracy: 0.9694 - val_loss: 0.0656 - val_accuracy: 0.9724\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1160 - accuracy: 0.9679 - val_loss: 0.0665 - val_accuracy: 0.9763\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1118 - accuracy: 0.9699 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1105 - accuracy: 0.9679 - val_loss: 0.0648 - val_accuracy: 0.9783\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1016 - accuracy: 0.9694 - val_loss: 0.0617 - val_accuracy: 0.9803\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9689 - val_loss: 0.0628 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1036 - accuracy: 0.9704 - val_loss: 0.0638 - val_accuracy: 0.9744\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1046 - accuracy: 0.9704 - val_loss: 0.0614 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9704 - val_loss: 0.0615 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1085 - accuracy: 0.9694 - val_loss: 0.0627 - val_accuracy: 0.9842\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1080 - accuracy: 0.9660 - val_loss: 0.0617 - val_accuracy: 0.9842\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1120 - accuracy: 0.9714 - val_loss: 0.0595 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0977 - accuracy: 0.9748 - val_loss: 0.0625 - val_accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0995 - accuracy: 0.9699 - val_loss: 0.0604 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1118 - accuracy: 0.9674 - val_loss: 0.0620 - val_accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0924 - accuracy: 0.9729 - val_loss: 0.0608 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.0636 - val_accuracy: 0.9744\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1038 - accuracy: 0.9743 - val_loss: 0.0648 - val_accuracy: 0.9744\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0984 - accuracy: 0.9743 - val_loss: 0.0605 - val_accuracy: 0.9763\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1033 - accuracy: 0.9743 - val_loss: 0.0597 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0958 - accuracy: 0.9753 - val_loss: 0.0599 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0976 - accuracy: 0.9743 - val_loss: 0.0658 - val_accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1110 - accuracy: 0.9704 - val_loss: 0.0581 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0966 - accuracy: 0.9729 - val_loss: 0.0607 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0980 - accuracy: 0.9724 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1022 - accuracy: 0.9758 - val_loss: 0.0590 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0995 - accuracy: 0.9739 - val_loss: 0.0595 - val_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0975 - accuracy: 0.9739 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1007 - accuracy: 0.9743 - val_loss: 0.0591 - val_accuracy: 0.9862\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0905 - accuracy: 0.9773 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0891 - accuracy: 0.9753 - val_loss: 0.0634 - val_accuracy: 0.9763\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9748 - val_loss: 0.0586 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.0583 - val_accuracy: 0.9783\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9719 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0933 - accuracy: 0.9748 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0947 - accuracy: 0.9743 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0929 - accuracy: 0.9758 - val_loss: 0.0597 - val_accuracy: 0.9763\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0952 - accuracy: 0.9739 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0966 - accuracy: 0.9714 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0837 - accuracy: 0.9753 - val_loss: 0.0593 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.9783 - val_loss: 0.0597 - val_accuracy: 0.9763\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 0.9758 - val_loss: 0.0576 - val_accuracy: 0.9803\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0904 - accuracy: 0.9739 - val_loss: 0.0587 - val_accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0921 - accuracy: 0.9773 - val_loss: 0.0557 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0921 - accuracy: 0.9748 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0889 - accuracy: 0.9778 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0916 - accuracy: 0.9739 - val_loss: 0.0585 - val_accuracy: 0.9783\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0946 - accuracy: 0.9753 - val_loss: 0.0576 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0872 - accuracy: 0.9758 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0877 - accuracy: 0.9734 - val_loss: 0.0557 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0845 - accuracy: 0.9778 - val_loss: 0.0584 - val_accuracy: 0.9783\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0850 - accuracy: 0.9753 - val_loss: 0.0625 - val_accuracy: 0.9763\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0918 - accuracy: 0.9724 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0856 - accuracy: 0.9773 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0832 - accuracy: 0.9768 - val_loss: 0.0563 - val_accuracy: 0.9803\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9768 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0874 - accuracy: 0.9753 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0935 - accuracy: 0.9734 - val_loss: 0.0552 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0868 - accuracy: 0.9768 - val_loss: 0.0583 - val_accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0851 - accuracy: 0.9778 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9739 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0873 - accuracy: 0.9788 - val_loss: 0.0567 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0818 - accuracy: 0.9783 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0907 - accuracy: 0.9763 - val_loss: 0.0541 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0842 - accuracy: 0.9768 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 35ms/step - loss: 0.6916 - accuracy: 0.5279 - val_loss: 0.6790 - val_accuracy: 0.7830\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6776 - accuracy: 0.6142 - val_loss: 0.6680 - val_accuracy: 0.7278\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6635 - accuracy: 0.6744 - val_loss: 0.6437 - val_accuracy: 0.8264\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6404 - accuracy: 0.7148 - val_loss: 0.6134 - val_accuracy: 0.7968\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6179 - accuracy: 0.7341 - val_loss: 0.5815 - val_accuracy: 0.8402\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5877 - accuracy: 0.7642 - val_loss: 0.5470 - val_accuracy: 0.8619\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5491 - accuracy: 0.7864 - val_loss: 0.4936 - val_accuracy: 0.8679\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5042 - accuracy: 0.8012 - val_loss: 0.4249 - val_accuracy: 0.8974\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4655 - accuracy: 0.8150 - val_loss: 0.3777 - val_accuracy: 0.9112\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4281 - accuracy: 0.8313 - val_loss: 0.3318 - val_accuracy: 0.9152\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3840 - accuracy: 0.8520 - val_loss: 0.2932 - val_accuracy: 0.9132\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3612 - accuracy: 0.8574 - val_loss: 0.2563 - val_accuracy: 0.9132\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3233 - accuracy: 0.8791 - val_loss: 0.2253 - val_accuracy: 0.9428\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2922 - accuracy: 0.8969 - val_loss: 0.1955 - val_accuracy: 0.9448\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2669 - accuracy: 0.9003 - val_loss: 0.1690 - val_accuracy: 0.9645\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2530 - accuracy: 0.9132 - val_loss: 0.1510 - val_accuracy: 0.9625\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2249 - accuracy: 0.9206 - val_loss: 0.1374 - val_accuracy: 0.9744\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2208 - accuracy: 0.9156 - val_loss: 0.1263 - val_accuracy: 0.9684\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1921 - accuracy: 0.9398 - val_loss: 0.1117 - val_accuracy: 0.9724\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1892 - accuracy: 0.9378 - val_loss: 0.1033 - val_accuracy: 0.9724\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1811 - accuracy: 0.9472 - val_loss: 0.0954 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1699 - accuracy: 0.9502 - val_loss: 0.0898 - val_accuracy: 0.9744\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1566 - accuracy: 0.9556 - val_loss: 0.0859 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1554 - accuracy: 0.9531 - val_loss: 0.0844 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1523 - accuracy: 0.9517 - val_loss: 0.0792 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1420 - accuracy: 0.9595 - val_loss: 0.0785 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1415 - accuracy: 0.9586 - val_loss: 0.0763 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1478 - accuracy: 0.9521 - val_loss: 0.0737 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1360 - accuracy: 0.9665 - val_loss: 0.0768 - val_accuracy: 0.9842\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1355 - accuracy: 0.9640 - val_loss: 0.0704 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1386 - accuracy: 0.9630 - val_loss: 0.0689 - val_accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1337 - accuracy: 0.9660 - val_loss: 0.0679 - val_accuracy: 0.9744\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1186 - accuracy: 0.9610 - val_loss: 0.0656 - val_accuracy: 0.9783\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1196 - accuracy: 0.9689 - val_loss: 0.0656 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1196 - accuracy: 0.9704 - val_loss: 0.0623 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1288 - accuracy: 0.9655 - val_loss: 0.0614 - val_accuracy: 0.9763\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1223 - accuracy: 0.9674 - val_loss: 0.0611 - val_accuracy: 0.9783\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1122 - accuracy: 0.9679 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1171 - accuracy: 0.9699 - val_loss: 0.0681 - val_accuracy: 0.9763\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1201 - accuracy: 0.9709 - val_loss: 0.0605 - val_accuracy: 0.9842\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1184 - accuracy: 0.9679 - val_loss: 0.0617 - val_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1224 - accuracy: 0.9704 - val_loss: 0.0572 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1194 - accuracy: 0.9734 - val_loss: 0.0583 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1111 - accuracy: 0.9743 - val_loss: 0.0569 - val_accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1143 - accuracy: 0.9719 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1086 - accuracy: 0.9763 - val_loss: 0.0565 - val_accuracy: 0.9744\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1133 - accuracy: 0.9763 - val_loss: 0.0544 - val_accuracy: 0.9763\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1089 - accuracy: 0.9714 - val_loss: 0.0579 - val_accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1053 - accuracy: 0.9724 - val_loss: 0.0555 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1123 - accuracy: 0.9729 - val_loss: 0.0541 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0991 - accuracy: 0.9739 - val_loss: 0.0644 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1209 - accuracy: 0.9655 - val_loss: 0.0534 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1098 - accuracy: 0.9743 - val_loss: 0.0527 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1090 - accuracy: 0.9758 - val_loss: 0.0521 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1033 - accuracy: 0.9748 - val_loss: 0.0505 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1001 - accuracy: 0.9699 - val_loss: 0.0518 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1051 - accuracy: 0.9734 - val_loss: 0.0512 - val_accuracy: 0.9763\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0998 - accuracy: 0.9763 - val_loss: 0.0508 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1059 - accuracy: 0.9714 - val_loss: 0.0491 - val_accuracy: 0.9842\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1091 - accuracy: 0.9753 - val_loss: 0.0621 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1022 - accuracy: 0.9719 - val_loss: 0.0541 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0967 - accuracy: 0.9763 - val_loss: 0.0475 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1014 - accuracy: 0.9793 - val_loss: 0.0492 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1043 - accuracy: 0.9734 - val_loss: 0.0486 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1018 - accuracy: 0.9758 - val_loss: 0.0466 - val_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0934 - accuracy: 0.9768 - val_loss: 0.0478 - val_accuracy: 0.9783\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9763 - val_loss: 0.0464 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0896 - accuracy: 0.9783 - val_loss: 0.0451 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0901 - accuracy: 0.9798 - val_loss: 0.0450 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0964 - accuracy: 0.9778 - val_loss: 0.0520 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0908 - accuracy: 0.9753 - val_loss: 0.0495 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0952 - accuracy: 0.9768 - val_loss: 0.0535 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0902 - accuracy: 0.9778 - val_loss: 0.0476 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0980 - accuracy: 0.9768 - val_loss: 0.0458 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0853 - accuracy: 0.9783 - val_loss: 0.0433 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0867 - accuracy: 0.9768 - val_loss: 0.0496 - val_accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0859 - accuracy: 0.9768 - val_loss: 0.0481 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0917 - accuracy: 0.9783 - val_loss: 0.0432 - val_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0875 - accuracy: 0.9788 - val_loss: 0.0458 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0791 - accuracy: 0.9788 - val_loss: 0.0450 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0835 - accuracy: 0.9763 - val_loss: 0.0429 - val_accuracy: 0.9842\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0877 - accuracy: 0.9753 - val_loss: 0.0521 - val_accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0901 - accuracy: 0.9748 - val_loss: 0.0470 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0878 - accuracy: 0.9758 - val_loss: 0.0448 - val_accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0847 - accuracy: 0.9788 - val_loss: 0.0433 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0788 - accuracy: 0.9773 - val_loss: 0.0455 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0812 - accuracy: 0.9768 - val_loss: 0.0440 - val_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0829 - accuracy: 0.9763 - val_loss: 0.0520 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0858 - accuracy: 0.9788 - val_loss: 0.0436 - val_accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 0.9768 - val_loss: 0.0431 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.0442 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0913 - accuracy: 0.9729 - val_loss: 0.0492 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0873 - accuracy: 0.9758 - val_loss: 0.0531 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0904 - accuracy: 0.9758 - val_loss: 0.0434 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0786 - accuracy: 0.9739 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0812 - accuracy: 0.9788 - val_loss: 0.0455 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0776 - accuracy: 0.9788 - val_loss: 0.0440 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0813 - accuracy: 0.9773 - val_loss: 0.0440 - val_accuracy: 0.9803\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0784 - accuracy: 0.9793 - val_loss: 0.0431 - val_accuracy: 0.9862\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0851 - accuracy: 0.9758 - val_loss: 0.0454 - val_accuracy: 0.9842\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7298 - accuracy: 0.4983 - val_loss: 0.6969 - val_accuracy: 0.5148\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6884 - accuracy: 0.5585 - val_loss: 0.6719 - val_accuracy: 0.6647\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6671 - accuracy: 0.6093 - val_loss: 0.6439 - val_accuracy: 0.6647\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6324 - accuracy: 0.6818 - val_loss: 0.5874 - val_accuracy: 0.7179\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5662 - accuracy: 0.7686 - val_loss: 0.5013 - val_accuracy: 0.8540\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5065 - accuracy: 0.8041 - val_loss: 0.4352 - val_accuracy: 0.8738\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4576 - accuracy: 0.8155 - val_loss: 0.3810 - val_accuracy: 0.8994\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4145 - accuracy: 0.8392 - val_loss: 0.3331 - val_accuracy: 0.9034\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3809 - accuracy: 0.8678 - val_loss: 0.3027 - val_accuracy: 0.9053\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3482 - accuracy: 0.8663 - val_loss: 0.2593 - val_accuracy: 0.9172\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3110 - accuracy: 0.9018 - val_loss: 0.2283 - val_accuracy: 0.9270\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2873 - accuracy: 0.9068 - val_loss: 0.1959 - val_accuracy: 0.9546\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2578 - accuracy: 0.9216 - val_loss: 0.1749 - val_accuracy: 0.9527\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2359 - accuracy: 0.9319 - val_loss: 0.1509 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2143 - accuracy: 0.9314 - val_loss: 0.1369 - val_accuracy: 0.9665\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1957 - accuracy: 0.9423 - val_loss: 0.1222 - val_accuracy: 0.9684\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1908 - accuracy: 0.9364 - val_loss: 0.1135 - val_accuracy: 0.9744\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1903 - accuracy: 0.9413 - val_loss: 0.1136 - val_accuracy: 0.9586\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1786 - accuracy: 0.9487 - val_loss: 0.1047 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1623 - accuracy: 0.9551 - val_loss: 0.0950 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1613 - accuracy: 0.9517 - val_loss: 0.0917 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1436 - accuracy: 0.9595 - val_loss: 0.0880 - val_accuracy: 0.9744\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1535 - accuracy: 0.9571 - val_loss: 0.0853 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1416 - accuracy: 0.9610 - val_loss: 0.0835 - val_accuracy: 0.9704\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1394 - accuracy: 0.9541 - val_loss: 0.0830 - val_accuracy: 0.9704\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1307 - accuracy: 0.9650 - val_loss: 0.0791 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1324 - accuracy: 0.9600 - val_loss: 0.0808 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1263 - accuracy: 0.9630 - val_loss: 0.0778 - val_accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1305 - accuracy: 0.9615 - val_loss: 0.0744 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1245 - accuracy: 0.9684 - val_loss: 0.0777 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1216 - accuracy: 0.9669 - val_loss: 0.0690 - val_accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1217 - accuracy: 0.9640 - val_loss: 0.0725 - val_accuracy: 0.9724\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1158 - accuracy: 0.9674 - val_loss: 0.0685 - val_accuracy: 0.9744\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1121 - accuracy: 0.9694 - val_loss: 0.0659 - val_accuracy: 0.9763\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1155 - accuracy: 0.9650 - val_loss: 0.0676 - val_accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1128 - accuracy: 0.9704 - val_loss: 0.0629 - val_accuracy: 0.9803\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 0.9684 - val_loss: 0.0615 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1080 - accuracy: 0.9724 - val_loss: 0.0605 - val_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1168 - accuracy: 0.9704 - val_loss: 0.0602 - val_accuracy: 0.9842\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1170 - accuracy: 0.9640 - val_loss: 0.0702 - val_accuracy: 0.9763\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1133 - accuracy: 0.9734 - val_loss: 0.0622 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1068 - accuracy: 0.9709 - val_loss: 0.0589 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1066 - accuracy: 0.9699 - val_loss: 0.0664 - val_accuracy: 0.9744\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1057 - accuracy: 0.9679 - val_loss: 0.0582 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1015 - accuracy: 0.9704 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1052 - accuracy: 0.9694 - val_loss: 0.0667 - val_accuracy: 0.9763\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1009 - accuracy: 0.9739 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0892 - accuracy: 0.9773 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1059 - accuracy: 0.9679 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0961 - accuracy: 0.9753 - val_loss: 0.0563 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0950 - accuracy: 0.9729 - val_loss: 0.0563 - val_accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0982 - accuracy: 0.9689 - val_loss: 0.0522 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9758 - val_loss: 0.0509 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0975 - accuracy: 0.9724 - val_loss: 0.0516 - val_accuracy: 0.9842\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0942 - accuracy: 0.9758 - val_loss: 0.0549 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0918 - accuracy: 0.9758 - val_loss: 0.0504 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0909 - accuracy: 0.9758 - val_loss: 0.0489 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0960 - accuracy: 0.9729 - val_loss: 0.0484 - val_accuracy: 0.9862\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0884 - accuracy: 0.9739 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.0517 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0997 - accuracy: 0.9763 - val_loss: 0.0494 - val_accuracy: 0.9783\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0963 - accuracy: 0.9743 - val_loss: 0.0509 - val_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0917 - accuracy: 0.9758 - val_loss: 0.0465 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0899 - accuracy: 0.9778 - val_loss: 0.0467 - val_accuracy: 0.9862\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0929 - accuracy: 0.9753 - val_loss: 0.0478 - val_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0894 - accuracy: 0.9773 - val_loss: 0.0467 - val_accuracy: 0.9842\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 0.0470 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0838 - accuracy: 0.9783 - val_loss: 0.0478 - val_accuracy: 0.9803\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0885 - accuracy: 0.9758 - val_loss: 0.0453 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 0.0550 - val_accuracy: 0.9783\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0915 - accuracy: 0.9768 - val_loss: 0.0452 - val_accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0846 - accuracy: 0.9773 - val_loss: 0.0466 - val_accuracy: 0.9803\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0827 - accuracy: 0.9773 - val_loss: 0.0491 - val_accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0893 - accuracy: 0.9724 - val_loss: 0.0484 - val_accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.0441 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0851 - accuracy: 0.9743 - val_loss: 0.0445 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0838 - accuracy: 0.9768 - val_loss: 0.0459 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0844 - accuracy: 0.9763 - val_loss: 0.0445 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0817 - accuracy: 0.9783 - val_loss: 0.0434 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0838 - accuracy: 0.9724 - val_loss: 0.0439 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0848 - accuracy: 0.9803 - val_loss: 0.0438 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0802 - accuracy: 0.9788 - val_loss: 0.0485 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9813 - val_loss: 0.0432 - val_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0822 - accuracy: 0.9763 - val_loss: 0.0445 - val_accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.9758 - val_loss: 0.0440 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.0462 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0853 - accuracy: 0.9743 - val_loss: 0.0430 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0819 - accuracy: 0.9748 - val_loss: 0.0445 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0779 - accuracy: 0.9778 - val_loss: 0.0463 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0800 - accuracy: 0.9778 - val_loss: 0.0456 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0775 - accuracy: 0.9763 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0739 - accuracy: 0.9778 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0789 - accuracy: 0.9758 - val_loss: 0.0422 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0711 - accuracy: 0.9793 - val_loss: 0.0454 - val_accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 0.9758 - val_loss: 0.0415 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0748 - accuracy: 0.9783 - val_loss: 0.0417 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 0.9793 - val_loss: 0.0442 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.0469 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9739 - val_loss: 0.0464 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0758 - accuracy: 0.9758 - val_loss: 0.0405 - val_accuracy: 0.9842\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_65 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 0.6984 - accuracy: 0.4958 - val_loss: 0.6868 - val_accuracy: 0.5128\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6783 - accuracy: 0.5195 - val_loss: 0.6694 - val_accuracy: 0.5247\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6577 - accuracy: 0.5703 - val_loss: 0.6440 - val_accuracy: 0.6568\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6336 - accuracy: 0.6438 - val_loss: 0.6127 - val_accuracy: 0.7022\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5999 - accuracy: 0.7074 - val_loss: 0.5738 - val_accuracy: 0.7456\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5713 - accuracy: 0.7607 - val_loss: 0.5355 - val_accuracy: 0.8107\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5332 - accuracy: 0.8086 - val_loss: 0.4939 - val_accuracy: 0.8797\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5015 - accuracy: 0.8293 - val_loss: 0.4539 - val_accuracy: 0.9093\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4682 - accuracy: 0.8574 - val_loss: 0.4178 - val_accuracy: 0.9191\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4500 - accuracy: 0.8688 - val_loss: 0.3893 - val_accuracy: 0.9310\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4154 - accuracy: 0.8757 - val_loss: 0.3531 - val_accuracy: 0.9290\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3914 - accuracy: 0.8791 - val_loss: 0.3276 - val_accuracy: 0.9250\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3740 - accuracy: 0.8851 - val_loss: 0.2986 - val_accuracy: 0.9250\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3396 - accuracy: 0.8999 - val_loss: 0.2669 - val_accuracy: 0.9310\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3210 - accuracy: 0.9028 - val_loss: 0.2469 - val_accuracy: 0.9329\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3089 - accuracy: 0.9063 - val_loss: 0.2264 - val_accuracy: 0.9428\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2839 - accuracy: 0.9201 - val_loss: 0.2007 - val_accuracy: 0.9645\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2497 - accuracy: 0.9280 - val_loss: 0.1764 - val_accuracy: 0.9704\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2558 - accuracy: 0.9304 - val_loss: 0.1668 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2380 - accuracy: 0.9408 - val_loss: 0.1558 - val_accuracy: 0.9763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2170 - accuracy: 0.9408 - val_loss: 0.1414 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2170 - accuracy: 0.9408 - val_loss: 0.1375 - val_accuracy: 0.9763\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2081 - accuracy: 0.9467 - val_loss: 0.1316 - val_accuracy: 0.9783\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1930 - accuracy: 0.9546 - val_loss: 0.1273 - val_accuracy: 0.9803\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.2072 - accuracy: 0.9492 - val_loss: 0.1245 - val_accuracy: 0.9783\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1913 - accuracy: 0.9571 - val_loss: 0.1205 - val_accuracy: 0.9704\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1838 - accuracy: 0.9536 - val_loss: 0.1269 - val_accuracy: 0.9665\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1878 - accuracy: 0.9546 - val_loss: 0.1154 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1821 - accuracy: 0.9556 - val_loss: 0.1121 - val_accuracy: 0.9803\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1727 - accuracy: 0.9615 - val_loss: 0.1081 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1749 - accuracy: 0.9630 - val_loss: 0.1060 - val_accuracy: 0.9783\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1588 - accuracy: 0.9645 - val_loss: 0.1024 - val_accuracy: 0.9724\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1776 - accuracy: 0.9556 - val_loss: 0.1054 - val_accuracy: 0.9724\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1738 - accuracy: 0.9635 - val_loss: 0.1029 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1690 - accuracy: 0.9630 - val_loss: 0.1013 - val_accuracy: 0.9783\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1641 - accuracy: 0.9650 - val_loss: 0.0994 - val_accuracy: 0.9783\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1621 - accuracy: 0.9650 - val_loss: 0.0972 - val_accuracy: 0.9803\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1562 - accuracy: 0.9655 - val_loss: 0.0989 - val_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1540 - accuracy: 0.9679 - val_loss: 0.0961 - val_accuracy: 0.9763\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1593 - accuracy: 0.9615 - val_loss: 0.0994 - val_accuracy: 0.9724\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1585 - accuracy: 0.9630 - val_loss: 0.0990 - val_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1562 - accuracy: 0.9655 - val_loss: 0.0980 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1495 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1499 - accuracy: 0.9689 - val_loss: 0.0921 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1488 - accuracy: 0.9704 - val_loss: 0.0904 - val_accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1505 - accuracy: 0.9679 - val_loss: 0.0923 - val_accuracy: 0.9763\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1586 - accuracy: 0.9665 - val_loss: 0.0932 - val_accuracy: 0.9842\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1469 - accuracy: 0.9674 - val_loss: 0.0882 - val_accuracy: 0.9803\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1482 - accuracy: 0.9684 - val_loss: 0.0892 - val_accuracy: 0.9803\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1417 - accuracy: 0.9743 - val_loss: 0.0885 - val_accuracy: 0.9744\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1471 - accuracy: 0.9699 - val_loss: 0.0877 - val_accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1446 - accuracy: 0.9689 - val_loss: 0.0839 - val_accuracy: 0.9783\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1478 - accuracy: 0.9655 - val_loss: 0.0872 - val_accuracy: 0.9842\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1405 - accuracy: 0.9699 - val_loss: 0.0857 - val_accuracy: 0.9842\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1482 - accuracy: 0.9694 - val_loss: 0.0827 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1407 - accuracy: 0.9669 - val_loss: 0.0824 - val_accuracy: 0.9763\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1424 - accuracy: 0.9694 - val_loss: 0.0796 - val_accuracy: 0.9803\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1358 - accuracy: 0.9704 - val_loss: 0.0852 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1350 - accuracy: 0.9748 - val_loss: 0.0789 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1325 - accuracy: 0.9734 - val_loss: 0.0766 - val_accuracy: 0.9783\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1330 - accuracy: 0.9729 - val_loss: 0.0756 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1360 - accuracy: 0.9719 - val_loss: 0.0777 - val_accuracy: 0.9842\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1284 - accuracy: 0.9719 - val_loss: 0.0755 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1304 - accuracy: 0.9719 - val_loss: 0.0767 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1300 - accuracy: 0.9734 - val_loss: 0.0731 - val_accuracy: 0.9763\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1315 - accuracy: 0.9729 - val_loss: 0.0752 - val_accuracy: 0.9842\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 0.9748 - val_loss: 0.0762 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1218 - accuracy: 0.9724 - val_loss: 0.0732 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1349 - accuracy: 0.9729 - val_loss: 0.0731 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1327 - accuracy: 0.9748 - val_loss: 0.0708 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1235 - accuracy: 0.9778 - val_loss: 0.0705 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1190 - accuracy: 0.9719 - val_loss: 0.0697 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1285 - accuracy: 0.9739 - val_loss: 0.0715 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1229 - accuracy: 0.9748 - val_loss: 0.0749 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1237 - accuracy: 0.9709 - val_loss: 0.0705 - val_accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1227 - accuracy: 0.9719 - val_loss: 0.0787 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1315 - accuracy: 0.9709 - val_loss: 0.0714 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1152 - accuracy: 0.9763 - val_loss: 0.0663 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1117 - accuracy: 0.9748 - val_loss: 0.0646 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1132 - accuracy: 0.9753 - val_loss: 0.0659 - val_accuracy: 0.9842\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1210 - accuracy: 0.9724 - val_loss: 0.0768 - val_accuracy: 0.9842\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1197 - accuracy: 0.9719 - val_loss: 0.0685 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1185 - accuracy: 0.9734 - val_loss: 0.0653 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1167 - accuracy: 0.9729 - val_loss: 0.0667 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1246 - accuracy: 0.9748 - val_loss: 0.0657 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1163 - accuracy: 0.9763 - val_loss: 0.0650 - val_accuracy: 0.9842\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1117 - accuracy: 0.9773 - val_loss: 0.0671 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1130 - accuracy: 0.9739 - val_loss: 0.0653 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1221 - accuracy: 0.9734 - val_loss: 0.0703 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9773 - val_loss: 0.0632 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1112 - accuracy: 0.9743 - val_loss: 0.0629 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1088 - accuracy: 0.9768 - val_loss: 0.0651 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.9714 - val_loss: 0.0686 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1142 - accuracy: 0.9748 - val_loss: 0.0626 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9793 - val_loss: 0.0616 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1039 - accuracy: 0.9768 - val_loss: 0.0616 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1074 - accuracy: 0.9753 - val_loss: 0.0601 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1113 - accuracy: 0.9743 - val_loss: 0.0614 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1084 - accuracy: 0.9753 - val_loss: 0.0623 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1090 - accuracy: 0.9768 - val_loss: 0.0658 - val_accuracy: 0.9822\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_132 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_66 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_67 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.6659 - accuracy: 0.6482 - val_loss: 0.6233 - val_accuracy: 0.8087\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6137 - accuracy: 0.7474 - val_loss: 0.5609 - val_accuracy: 0.8856\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5576 - accuracy: 0.7933 - val_loss: 0.4989 - val_accuracy: 0.9093\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5046 - accuracy: 0.8318 - val_loss: 0.4337 - val_accuracy: 0.9132\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4584 - accuracy: 0.8416 - val_loss: 0.3787 - val_accuracy: 0.9191\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4178 - accuracy: 0.8599 - val_loss: 0.3262 - val_accuracy: 0.9172\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3758 - accuracy: 0.8727 - val_loss: 0.2796 - val_accuracy: 0.9231\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3460 - accuracy: 0.8806 - val_loss: 0.2421 - val_accuracy: 0.9349\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3180 - accuracy: 0.8920 - val_loss: 0.2109 - val_accuracy: 0.9389\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2802 - accuracy: 0.9053 - val_loss: 0.1828 - val_accuracy: 0.9586\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2579 - accuracy: 0.9142 - val_loss: 0.1589 - val_accuracy: 0.9625\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2336 - accuracy: 0.9265 - val_loss: 0.1407 - val_accuracy: 0.9625\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2120 - accuracy: 0.9334 - val_loss: 0.1294 - val_accuracy: 0.9625\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1956 - accuracy: 0.9388 - val_loss: 0.1192 - val_accuracy: 0.9724\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1863 - accuracy: 0.9482 - val_loss: 0.1068 - val_accuracy: 0.9704\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1804 - accuracy: 0.9413 - val_loss: 0.1026 - val_accuracy: 0.9704\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1583 - accuracy: 0.9566 - val_loss: 0.0975 - val_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1510 - accuracy: 0.9576 - val_loss: 0.0926 - val_accuracy: 0.9704\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1476 - accuracy: 0.9561 - val_loss: 0.0911 - val_accuracy: 0.9684\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1394 - accuracy: 0.9605 - val_loss: 0.0874 - val_accuracy: 0.9704\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1345 - accuracy: 0.9591 - val_loss: 0.0849 - val_accuracy: 0.9704\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1337 - accuracy: 0.9640 - val_loss: 0.0837 - val_accuracy: 0.9704\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1295 - accuracy: 0.9630 - val_loss: 0.0847 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1331 - accuracy: 0.9610 - val_loss: 0.0822 - val_accuracy: 0.9704\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1234 - accuracy: 0.9699 - val_loss: 0.0806 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1234 - accuracy: 0.9620 - val_loss: 0.0896 - val_accuracy: 0.9665\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1342 - accuracy: 0.9595 - val_loss: 0.0797 - val_accuracy: 0.9704\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1189 - accuracy: 0.9635 - val_loss: 0.0891 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1263 - accuracy: 0.9674 - val_loss: 0.0759 - val_accuracy: 0.9704\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1226 - accuracy: 0.9665 - val_loss: 0.0777 - val_accuracy: 0.9744\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1218 - accuracy: 0.9640 - val_loss: 0.0776 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.9679 - val_loss: 0.0809 - val_accuracy: 0.9704\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1189 - accuracy: 0.9655 - val_loss: 0.0748 - val_accuracy: 0.9704\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1101 - accuracy: 0.9689 - val_loss: 0.0808 - val_accuracy: 0.9783\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1128 - accuracy: 0.9704 - val_loss: 0.0735 - val_accuracy: 0.9724\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9699 - val_loss: 0.0798 - val_accuracy: 0.9704\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9729 - val_loss: 0.0738 - val_accuracy: 0.9704\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1106 - accuracy: 0.9669 - val_loss: 0.0740 - val_accuracy: 0.9724\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1095 - accuracy: 0.9684 - val_loss: 0.0750 - val_accuracy: 0.9724\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1096 - accuracy: 0.9719 - val_loss: 0.0723 - val_accuracy: 0.9783\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1133 - accuracy: 0.9674 - val_loss: 0.0704 - val_accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 0.9694 - val_loss: 0.0700 - val_accuracy: 0.9724\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1004 - accuracy: 0.9724 - val_loss: 0.0694 - val_accuracy: 0.9724\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1180 - accuracy: 0.9694 - val_loss: 0.0735 - val_accuracy: 0.9704\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1155 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9684\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1141 - accuracy: 0.9689 - val_loss: 0.0775 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.0672 - val_accuracy: 0.9744\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1057 - accuracy: 0.9719 - val_loss: 0.0685 - val_accuracy: 0.9704\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1063 - accuracy: 0.9714 - val_loss: 0.0664 - val_accuracy: 0.9744\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1003 - accuracy: 0.9753 - val_loss: 0.0675 - val_accuracy: 0.9744\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1068 - accuracy: 0.9704 - val_loss: 0.0655 - val_accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1026 - accuracy: 0.9714 - val_loss: 0.0668 - val_accuracy: 0.9763\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - accuracy: 0.9758 - val_loss: 0.0638 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 0.0654 - val_accuracy: 0.9783\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1005 - accuracy: 0.9758 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.0633 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0994 - accuracy: 0.9758 - val_loss: 0.0631 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1029 - accuracy: 0.9709 - val_loss: 0.0621 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9714 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0969 - accuracy: 0.9739 - val_loss: 0.0605 - val_accuracy: 0.9783\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1003 - accuracy: 0.9743 - val_loss: 0.0626 - val_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0945 - accuracy: 0.9729 - val_loss: 0.0741 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0971 - accuracy: 0.9719 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0913 - accuracy: 0.9763 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.9734 - val_loss: 0.0599 - val_accuracy: 0.9803\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0947 - accuracy: 0.9748 - val_loss: 0.0579 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0940 - accuracy: 0.9753 - val_loss: 0.0603 - val_accuracy: 0.9783\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0899 - accuracy: 0.9743 - val_loss: 0.0616 - val_accuracy: 0.9783\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.0599 - val_accuracy: 0.9803\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0915 - accuracy: 0.9768 - val_loss: 0.0589 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9758 - val_loss: 0.0593 - val_accuracy: 0.9803\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0903 - accuracy: 0.9743 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0942 - accuracy: 0.9753 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0903 - accuracy: 0.9763 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.9773 - val_loss: 0.0534 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0918 - accuracy: 0.9748 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0857 - accuracy: 0.9773 - val_loss: 0.0542 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0893 - accuracy: 0.9768 - val_loss: 0.0556 - val_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0914 - accuracy: 0.9768 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.9798 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0929 - accuracy: 0.9734 - val_loss: 0.0583 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0877 - accuracy: 0.9778 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.9773 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0864 - accuracy: 0.9763 - val_loss: 0.0523 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0820 - accuracy: 0.9778 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.9768 - val_loss: 0.0515 - val_accuracy: 0.9862\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0866 - accuracy: 0.9778 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0863 - accuracy: 0.9763 - val_loss: 0.0559 - val_accuracy: 0.9803\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0843 - accuracy: 0.9783 - val_loss: 0.0542 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0797 - accuracy: 0.9773 - val_loss: 0.0533 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0883 - accuracy: 0.9793 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0861 - accuracy: 0.9783 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0840 - accuracy: 0.9773 - val_loss: 0.0522 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0846 - accuracy: 0.9788 - val_loss: 0.0556 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0874 - accuracy: 0.9763 - val_loss: 0.0564 - val_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9773 - val_loss: 0.0572 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0906 - accuracy: 0.9773 - val_loss: 0.0508 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0797 - accuracy: 0.9793 - val_loss: 0.0539 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9783 - val_loss: 0.0557 - val_accuracy: 0.9822\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_68 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_69 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 23ms/step - loss: 0.6650 - accuracy: 0.5392 - val_loss: 0.6414 - val_accuracy: 0.6055\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6342 - accuracy: 0.5777 - val_loss: 0.6122 - val_accuracy: 0.6450\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6089 - accuracy: 0.6428 - val_loss: 0.5844 - val_accuracy: 0.7081\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5792 - accuracy: 0.6971 - val_loss: 0.5540 - val_accuracy: 0.7239\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5547 - accuracy: 0.7375 - val_loss: 0.5223 - val_accuracy: 0.7988\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5262 - accuracy: 0.7859 - val_loss: 0.4879 - val_accuracy: 0.8264\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4976 - accuracy: 0.8259 - val_loss: 0.4523 - val_accuracy: 0.8462\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4620 - accuracy: 0.8382 - val_loss: 0.4171 - val_accuracy: 0.8718\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4377 - accuracy: 0.8579 - val_loss: 0.3822 - val_accuracy: 0.8994\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4033 - accuracy: 0.8801 - val_loss: 0.3466 - val_accuracy: 0.9152\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8855 - val_loss: 0.3144 - val_accuracy: 0.9172\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3461 - accuracy: 0.8984 - val_loss: 0.2712 - val_accuracy: 0.9487\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3205 - accuracy: 0.9073 - val_loss: 0.2421 - val_accuracy: 0.9684\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2963 - accuracy: 0.9156 - val_loss: 0.2165 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2671 - accuracy: 0.9255 - val_loss: 0.1893 - val_accuracy: 0.9665\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2441 - accuracy: 0.9344 - val_loss: 0.1648 - val_accuracy: 0.9744\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2276 - accuracy: 0.9403 - val_loss: 0.1492 - val_accuracy: 0.9822\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.2065 - accuracy: 0.9512 - val_loss: 0.1316 - val_accuracy: 0.9803\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1981 - accuracy: 0.9492 - val_loss: 0.1185 - val_accuracy: 0.9842\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1904 - accuracy: 0.9487 - val_loss: 0.1121 - val_accuracy: 0.9822\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1804 - accuracy: 0.9502 - val_loss: 0.1088 - val_accuracy: 0.9803\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1691 - accuracy: 0.9615 - val_loss: 0.1046 - val_accuracy: 0.9842\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1591 - accuracy: 0.9561 - val_loss: 0.0909 - val_accuracy: 0.9822\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1536 - accuracy: 0.9605 - val_loss: 0.0865 - val_accuracy: 0.9862\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.9561 - val_loss: 0.0843 - val_accuracy: 0.9842\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1526 - accuracy: 0.9595 - val_loss: 0.0833 - val_accuracy: 0.9822\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1530 - accuracy: 0.9595 - val_loss: 0.0800 - val_accuracy: 0.9803\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1466 - accuracy: 0.9630 - val_loss: 0.0785 - val_accuracy: 0.9803\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1435 - accuracy: 0.9591 - val_loss: 0.0758 - val_accuracy: 0.9842\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1471 - accuracy: 0.9630 - val_loss: 0.0747 - val_accuracy: 0.9822\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1413 - accuracy: 0.9650 - val_loss: 0.0726 - val_accuracy: 0.9822\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1500 - accuracy: 0.9600 - val_loss: 0.0796 - val_accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1345 - accuracy: 0.9684 - val_loss: 0.0706 - val_accuracy: 0.9862\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.9689 - val_loss: 0.0701 - val_accuracy: 0.9862\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9615 - val_loss: 0.0683 - val_accuracy: 0.9862\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1279 - accuracy: 0.9694 - val_loss: 0.0664 - val_accuracy: 0.9822\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1318 - accuracy: 0.9660 - val_loss: 0.0666 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1341 - accuracy: 0.9674 - val_loss: 0.0710 - val_accuracy: 0.9744\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9699 - val_loss: 0.0641 - val_accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1225 - accuracy: 0.9719 - val_loss: 0.0650 - val_accuracy: 0.9882\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1204 - accuracy: 0.9704 - val_loss: 0.0606 - val_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1257 - accuracy: 0.9665 - val_loss: 0.0583 - val_accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1278 - accuracy: 0.9660 - val_loss: 0.0604 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1204 - accuracy: 0.9665 - val_loss: 0.0676 - val_accuracy: 0.9763\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1191 - accuracy: 0.9704 - val_loss: 0.0580 - val_accuracy: 0.9862\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 0.9694 - val_loss: 0.0587 - val_accuracy: 0.9822\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1179 - accuracy: 0.9709 - val_loss: 0.0573 - val_accuracy: 0.9842\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1215 - accuracy: 0.9694 - val_loss: 0.0577 - val_accuracy: 0.9882\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1197 - accuracy: 0.9694 - val_loss: 0.0640 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1240 - accuracy: 0.9674 - val_loss: 0.0572 - val_accuracy: 0.9822\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1261 - accuracy: 0.9674 - val_loss: 0.0559 - val_accuracy: 0.9862\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1171 - accuracy: 0.9748 - val_loss: 0.0552 - val_accuracy: 0.9822\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1162 - accuracy: 0.9719 - val_loss: 0.0561 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1173 - accuracy: 0.9709 - val_loss: 0.0583 - val_accuracy: 0.9862\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1186 - accuracy: 0.9694 - val_loss: 0.0599 - val_accuracy: 0.9862\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1096 - accuracy: 0.9748 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1107 - accuracy: 0.9684 - val_loss: 0.0545 - val_accuracy: 0.9862\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1134 - accuracy: 0.9748 - val_loss: 0.0640 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 0.9709 - val_loss: 0.0525 - val_accuracy: 0.9862\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1163 - accuracy: 0.9724 - val_loss: 0.0583 - val_accuracy: 0.9862\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0988 - accuracy: 0.9768 - val_loss: 0.0590 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1077 - accuracy: 0.9719 - val_loss: 0.0554 - val_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1066 - accuracy: 0.9729 - val_loss: 0.0496 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1037 - accuracy: 0.9743 - val_loss: 0.0515 - val_accuracy: 0.9862\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1092 - accuracy: 0.9729 - val_loss: 0.0481 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1012 - accuracy: 0.9739 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 0.9734 - val_loss: 0.0471 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 0.9709 - val_loss: 0.0477 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9709 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 0.9729 - val_loss: 0.0479 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.0496 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0998 - accuracy: 0.9773 - val_loss: 0.0474 - val_accuracy: 0.9842\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1042 - accuracy: 0.9743 - val_loss: 0.0456 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.9778 - val_loss: 0.0499 - val_accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9763 - val_loss: 0.0456 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0931 - accuracy: 0.9753 - val_loss: 0.0450 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0991 - accuracy: 0.9758 - val_loss: 0.0441 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1015 - accuracy: 0.9719 - val_loss: 0.0589 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1002 - accuracy: 0.9753 - val_loss: 0.0476 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0988 - accuracy: 0.9768 - val_loss: 0.0482 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9753 - val_loss: 0.0447 - val_accuracy: 0.9842\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9748 - val_loss: 0.0494 - val_accuracy: 0.9842\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0985 - accuracy: 0.9783 - val_loss: 0.0510 - val_accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0948 - accuracy: 0.9773 - val_loss: 0.0441 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.9778 - val_loss: 0.0454 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0879 - accuracy: 0.9753 - val_loss: 0.0481 - val_accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0998 - accuracy: 0.9719 - val_loss: 0.0439 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.9793 - val_loss: 0.0438 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0976 - accuracy: 0.9753 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0957 - accuracy: 0.9734 - val_loss: 0.0497 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1033 - accuracy: 0.9734 - val_loss: 0.0439 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0942 - accuracy: 0.9753 - val_loss: 0.0443 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0929 - accuracy: 0.9729 - val_loss: 0.0467 - val_accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0902 - accuracy: 0.9788 - val_loss: 0.0434 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.9743 - val_loss: 0.0458 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0940 - accuracy: 0.9783 - val_loss: 0.0441 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9778 - val_loss: 0.0443 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0913 - accuracy: 0.9783 - val_loss: 0.0400 - val_accuracy: 0.9882\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0908 - accuracy: 0.9768 - val_loss: 0.0416 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0935 - accuracy: 0.9748 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_70 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_71 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 28ms/step - loss: 0.7141 - accuracy: 0.4963 - val_loss: 0.6855 - val_accuracy: 0.4931\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.5881 - val_loss: 0.6603 - val_accuracy: 0.7436\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6532 - accuracy: 0.7144 - val_loss: 0.6313 - val_accuracy: 0.7495\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6258 - accuracy: 0.7390 - val_loss: 0.5943 - val_accuracy: 0.8146\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5944 - accuracy: 0.7741 - val_loss: 0.5502 - val_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5561 - accuracy: 0.8066 - val_loss: 0.5018 - val_accuracy: 0.8698\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5145 - accuracy: 0.8342 - val_loss: 0.4516 - val_accuracy: 0.8955\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4736 - accuracy: 0.8397 - val_loss: 0.4077 - val_accuracy: 0.9073\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4297 - accuracy: 0.8569 - val_loss: 0.3549 - val_accuracy: 0.9290\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8693 - val_loss: 0.2983 - val_accuracy: 0.9270\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3419 - accuracy: 0.8959 - val_loss: 0.2580 - val_accuracy: 0.9467\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3179 - accuracy: 0.9023 - val_loss: 0.2315 - val_accuracy: 0.9586\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2709 - accuracy: 0.9304 - val_loss: 0.1902 - val_accuracy: 0.9428\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2544 - accuracy: 0.9270 - val_loss: 0.1650 - val_accuracy: 0.9467\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2224 - accuracy: 0.9388 - val_loss: 0.1454 - val_accuracy: 0.9586\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2115 - accuracy: 0.9413 - val_loss: 0.1333 - val_accuracy: 0.9586\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1856 - accuracy: 0.9526 - val_loss: 0.1210 - val_accuracy: 0.9606\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1796 - accuracy: 0.9512 - val_loss: 0.1156 - val_accuracy: 0.9586\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1761 - accuracy: 0.9517 - val_loss: 0.1029 - val_accuracy: 0.9724\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1594 - accuracy: 0.9566 - val_loss: 0.0985 - val_accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1619 - accuracy: 0.9546 - val_loss: 0.1004 - val_accuracy: 0.9665\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1543 - accuracy: 0.9605 - val_loss: 0.0898 - val_accuracy: 0.9744\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1330 - accuracy: 0.9655 - val_loss: 0.0848 - val_accuracy: 0.9684\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1455 - accuracy: 0.9591 - val_loss: 0.0863 - val_accuracy: 0.9704\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1442 - accuracy: 0.9640 - val_loss: 0.0858 - val_accuracy: 0.9704\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1311 - accuracy: 0.9650 - val_loss: 0.0772 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1267 - accuracy: 0.9660 - val_loss: 0.0754 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1259 - accuracy: 0.9650 - val_loss: 0.0717 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1269 - accuracy: 0.9689 - val_loss: 0.0814 - val_accuracy: 0.9704\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1230 - accuracy: 0.9674 - val_loss: 0.0735 - val_accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1236 - accuracy: 0.9699 - val_loss: 0.0690 - val_accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1191 - accuracy: 0.9709 - val_loss: 0.0680 - val_accuracy: 0.9744\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1167 - accuracy: 0.9679 - val_loss: 0.0692 - val_accuracy: 0.9763\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1228 - accuracy: 0.9684 - val_loss: 0.0657 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1209 - accuracy: 0.9729 - val_loss: 0.0688 - val_accuracy: 0.9724\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1034 - accuracy: 0.9729 - val_loss: 0.0656 - val_accuracy: 0.9763\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1166 - accuracy: 0.9699 - val_loss: 0.0706 - val_accuracy: 0.9704\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1116 - accuracy: 0.9729 - val_loss: 0.0633 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 0.9739 - val_loss: 0.0633 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1075 - accuracy: 0.9763 - val_loss: 0.0677 - val_accuracy: 0.9724\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0986 - accuracy: 0.9739 - val_loss: 0.0628 - val_accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1066 - accuracy: 0.9709 - val_loss: 0.0633 - val_accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.9724 - val_loss: 0.0612 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1054 - accuracy: 0.9763 - val_loss: 0.0591 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9739 - val_loss: 0.0661 - val_accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1061 - accuracy: 0.9729 - val_loss: 0.0596 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1015 - accuracy: 0.9729 - val_loss: 0.0637 - val_accuracy: 0.9724\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1050 - accuracy: 0.9783 - val_loss: 0.0615 - val_accuracy: 0.9763\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9719 - val_loss: 0.0576 - val_accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0943 - accuracy: 0.9748 - val_loss: 0.0624 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0935 - accuracy: 0.9743 - val_loss: 0.0570 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0987 - accuracy: 0.9778 - val_loss: 0.0563 - val_accuracy: 0.9783\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0960 - accuracy: 0.9783 - val_loss: 0.0564 - val_accuracy: 0.9803\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0922 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0969 - accuracy: 0.9743 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0924 - accuracy: 0.9768 - val_loss: 0.0546 - val_accuracy: 0.9803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0942 - accuracy: 0.9758 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9753 - val_loss: 0.0545 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0959 - accuracy: 0.9763 - val_loss: 0.0556 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0958 - accuracy: 0.9768 - val_loss: 0.0629 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0950 - accuracy: 0.9788 - val_loss: 0.0547 - val_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9763 - val_loss: 0.0571 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9763 - val_loss: 0.0600 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0946 - accuracy: 0.9773 - val_loss: 0.0550 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0859 - accuracy: 0.9808 - val_loss: 0.0547 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0896 - accuracy: 0.9798 - val_loss: 0.0548 - val_accuracy: 0.9803\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0940 - accuracy: 0.9753 - val_loss: 0.0573 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0892 - accuracy: 0.9773 - val_loss: 0.0610 - val_accuracy: 0.9803\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0922 - accuracy: 0.9753 - val_loss: 0.0542 - val_accuracy: 0.9783\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0883 - accuracy: 0.9768 - val_loss: 0.0548 - val_accuracy: 0.9803\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9808 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0883 - accuracy: 0.9768 - val_loss: 0.0586 - val_accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0840 - accuracy: 0.9768 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0904 - accuracy: 0.9783 - val_loss: 0.0539 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0874 - accuracy: 0.9793 - val_loss: 0.0537 - val_accuracy: 0.9803\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0877 - accuracy: 0.9817 - val_loss: 0.0528 - val_accuracy: 0.9783\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0873 - accuracy: 0.9783 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0840 - accuracy: 0.9803 - val_loss: 0.0555 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0927 - accuracy: 0.9803 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9798 - val_loss: 0.0582 - val_accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0831 - accuracy: 0.9798 - val_loss: 0.0570 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9803 - val_loss: 0.0545 - val_accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.9808 - val_loss: 0.0531 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0793 - accuracy: 0.9817 - val_loss: 0.0544 - val_accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0877 - accuracy: 0.9803 - val_loss: 0.0552 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0860 - accuracy: 0.9808 - val_loss: 0.0543 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.9822 - val_loss: 0.0554 - val_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0880 - accuracy: 0.9788 - val_loss: 0.0529 - val_accuracy: 0.9803\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0837 - accuracy: 0.9793 - val_loss: 0.0538 - val_accuracy: 0.9803\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.9832 - val_loss: 0.0528 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0763 - accuracy: 0.9817 - val_loss: 0.0527 - val_accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0788 - accuracy: 0.9827 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9822 - val_loss: 0.0556 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0835 - accuracy: 0.9793 - val_loss: 0.0508 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0821 - accuracy: 0.9798 - val_loss: 0.0539 - val_accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9832 - val_loss: 0.0547 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0776 - accuracy: 0.9817 - val_loss: 0.0528 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9808 - val_loss: 0.0529 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0769 - accuracy: 0.9817 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.9798 - val_loss: 0.0523 - val_accuracy: 0.9803\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_72 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_73 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6769 - val_accuracy: 0.5444\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6660 - accuracy: 0.5461 - val_loss: 0.6538 - val_accuracy: 0.5661\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.6531 - accuracy: 0.5772 - val_loss: 0.6314 - val_accuracy: 0.6568\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6250 - accuracy: 0.6527 - val_loss: 0.6084 - val_accuracy: 0.7179\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6079 - accuracy: 0.7010 - val_loss: 0.5828 - val_accuracy: 0.7318\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.5836 - accuracy: 0.7292 - val_loss: 0.5510 - val_accuracy: 0.7732\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5509 - accuracy: 0.7607 - val_loss: 0.5125 - val_accuracy: 0.8205\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5238 - accuracy: 0.8037 - val_loss: 0.4731 - val_accuracy: 0.8895\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4914 - accuracy: 0.8313 - val_loss: 0.4430 - val_accuracy: 0.9290\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4666 - accuracy: 0.8653 - val_loss: 0.4157 - val_accuracy: 0.9448\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4345 - accuracy: 0.9028 - val_loss: 0.3855 - val_accuracy: 0.9487\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4171 - accuracy: 0.9166 - val_loss: 0.3636 - val_accuracy: 0.9586\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.9324 - val_loss: 0.3459 - val_accuracy: 0.9586\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3733 - accuracy: 0.9428 - val_loss: 0.3309 - val_accuracy: 0.9684\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3657 - accuracy: 0.9546 - val_loss: 0.3166 - val_accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3446 - accuracy: 0.9566 - val_loss: 0.3038 - val_accuracy: 0.9783\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3321 - accuracy: 0.9586 - val_loss: 0.2934 - val_accuracy: 0.9783\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3186 - accuracy: 0.9665 - val_loss: 0.2808 - val_accuracy: 0.9783\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3122 - accuracy: 0.9650 - val_loss: 0.2678 - val_accuracy: 0.9803\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.2984 - accuracy: 0.9650 - val_loss: 0.2561 - val_accuracy: 0.9822\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2786 - accuracy: 0.9615 - val_loss: 0.2183 - val_accuracy: 0.9842\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2525 - accuracy: 0.9551 - val_loss: 0.1917 - val_accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2271 - accuracy: 0.9531 - val_loss: 0.1778 - val_accuracy: 0.9625\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2101 - accuracy: 0.9536 - val_loss: 0.1552 - val_accuracy: 0.9645\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1979 - accuracy: 0.9551 - val_loss: 0.1297 - val_accuracy: 0.9822\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1854 - accuracy: 0.9521 - val_loss: 0.1252 - val_accuracy: 0.9842\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1895 - accuracy: 0.9536 - val_loss: 0.1115 - val_accuracy: 0.9803\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1680 - accuracy: 0.9615 - val_loss: 0.1092 - val_accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1659 - accuracy: 0.9605 - val_loss: 0.1047 - val_accuracy: 0.9704\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1645 - accuracy: 0.9600 - val_loss: 0.1013 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1559 - accuracy: 0.9600 - val_loss: 0.0949 - val_accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1540 - accuracy: 0.9600 - val_loss: 0.0892 - val_accuracy: 0.9822\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1512 - accuracy: 0.9610 - val_loss: 0.0906 - val_accuracy: 0.9822\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1419 - accuracy: 0.9605 - val_loss: 0.0888 - val_accuracy: 0.9822\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1458 - accuracy: 0.9630 - val_loss: 0.0833 - val_accuracy: 0.9842\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1494 - accuracy: 0.9620 - val_loss: 0.0826 - val_accuracy: 0.9842\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1429 - accuracy: 0.9655 - val_loss: 0.0800 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1330 - accuracy: 0.9665 - val_loss: 0.0828 - val_accuracy: 0.9882\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1298 - accuracy: 0.9669 - val_loss: 0.0780 - val_accuracy: 0.9862\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1327 - accuracy: 0.9684 - val_loss: 0.0749 - val_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1268 - accuracy: 0.9684 - val_loss: 0.0789 - val_accuracy: 0.9882\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1265 - accuracy: 0.9669 - val_loss: 0.0769 - val_accuracy: 0.9882\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1300 - accuracy: 0.9689 - val_loss: 0.0703 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1231 - accuracy: 0.9689 - val_loss: 0.0723 - val_accuracy: 0.9842\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1177 - accuracy: 0.9704 - val_loss: 0.0714 - val_accuracy: 0.9763\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1140 - accuracy: 0.9694 - val_loss: 0.0663 - val_accuracy: 0.9822\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1280 - accuracy: 0.9665 - val_loss: 0.0663 - val_accuracy: 0.9862\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1179 - accuracy: 0.9709 - val_loss: 0.0678 - val_accuracy: 0.9862\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1247 - accuracy: 0.9689 - val_loss: 0.0646 - val_accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1232 - accuracy: 0.9689 - val_loss: 0.0668 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1279 - accuracy: 0.9660 - val_loss: 0.0666 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1218 - accuracy: 0.9679 - val_loss: 0.0664 - val_accuracy: 0.9862\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1127 - accuracy: 0.9704 - val_loss: 0.0618 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1089 - accuracy: 0.9734 - val_loss: 0.0615 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1170 - accuracy: 0.9674 - val_loss: 0.0674 - val_accuracy: 0.9862\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1202 - accuracy: 0.9714 - val_loss: 0.0648 - val_accuracy: 0.9882\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1081 - accuracy: 0.9724 - val_loss: 0.0623 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1016 - accuracy: 0.9734 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1102 - accuracy: 0.9704 - val_loss: 0.0584 - val_accuracy: 0.9862\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1047 - accuracy: 0.9743 - val_loss: 0.0603 - val_accuracy: 0.9842\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1055 - accuracy: 0.9734 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 0.9729 - val_loss: 0.0746 - val_accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1121 - accuracy: 0.9714 - val_loss: 0.0554 - val_accuracy: 0.9862\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1059 - accuracy: 0.9724 - val_loss: 0.0556 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1058 - accuracy: 0.9729 - val_loss: 0.0555 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1066 - accuracy: 0.9773 - val_loss: 0.0592 - val_accuracy: 0.9763\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1032 - accuracy: 0.9724 - val_loss: 0.0596 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1025 - accuracy: 0.9734 - val_loss: 0.0604 - val_accuracy: 0.9842\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1008 - accuracy: 0.9753 - val_loss: 0.0575 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0985 - accuracy: 0.9743 - val_loss: 0.0548 - val_accuracy: 0.9862\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0944 - accuracy: 0.9753 - val_loss: 0.0540 - val_accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0933 - accuracy: 0.9763 - val_loss: 0.0519 - val_accuracy: 0.9862\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.9739 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0998 - accuracy: 0.9748 - val_loss: 0.0549 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0894 - accuracy: 0.9729 - val_loss: 0.0644 - val_accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9758 - val_loss: 0.0529 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0894 - accuracy: 0.9778 - val_loss: 0.0507 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9748 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0950 - accuracy: 0.9768 - val_loss: 0.0526 - val_accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0952 - accuracy: 0.9739 - val_loss: 0.0506 - val_accuracy: 0.9842\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0979 - accuracy: 0.9783 - val_loss: 0.0514 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0944 - accuracy: 0.9753 - val_loss: 0.0520 - val_accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0940 - accuracy: 0.9753 - val_loss: 0.0528 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0911 - accuracy: 0.9773 - val_loss: 0.0499 - val_accuracy: 0.9862\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0941 - accuracy: 0.9743 - val_loss: 0.0541 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 0.0493 - val_accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0973 - accuracy: 0.9793 - val_loss: 0.0480 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0912 - accuracy: 0.9783 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0949 - accuracy: 0.9783 - val_loss: 0.0493 - val_accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0905 - accuracy: 0.9793 - val_loss: 0.0538 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0841 - accuracy: 0.9778 - val_loss: 0.0516 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9798 - val_loss: 0.0491 - val_accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0938 - accuracy: 0.9743 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0942 - accuracy: 0.9758 - val_loss: 0.0519 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0907 - accuracy: 0.9773 - val_loss: 0.0500 - val_accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0846 - accuracy: 0.9778 - val_loss: 0.0494 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0853 - accuracy: 0.9773 - val_loss: 0.0472 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0933 - accuracy: 0.9758 - val_loss: 0.0479 - val_accuracy: 0.9842\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0826 - accuracy: 0.9778 - val_loss: 0.0515 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9788 - val_loss: 0.0500 - val_accuracy: 0.9842\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_74 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_75 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 30ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6767 - val_accuracy: 0.6548\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6788 - accuracy: 0.5821 - val_loss: 0.6603 - val_accuracy: 0.8067\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6604 - accuracy: 0.6714 - val_loss: 0.6360 - val_accuracy: 0.8205\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6351 - accuracy: 0.7247 - val_loss: 0.6043 - val_accuracy: 0.8185\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6023 - accuracy: 0.7597 - val_loss: 0.5605 - val_accuracy: 0.8343\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5777 - accuracy: 0.7657 - val_loss: 0.5203 - val_accuracy: 0.8462\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5418 - accuracy: 0.7869 - val_loss: 0.4739 - val_accuracy: 0.8580\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5075 - accuracy: 0.7992 - val_loss: 0.4308 - val_accuracy: 0.8777\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4620 - accuracy: 0.8328 - val_loss: 0.3926 - val_accuracy: 0.8777\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4325 - accuracy: 0.8377 - val_loss: 0.3470 - val_accuracy: 0.9073\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4036 - accuracy: 0.8515 - val_loss: 0.3100 - val_accuracy: 0.9231\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3794 - accuracy: 0.8658 - val_loss: 0.2746 - val_accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3505 - accuracy: 0.8762 - val_loss: 0.2446 - val_accuracy: 0.9250\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3172 - accuracy: 0.8860 - val_loss: 0.2214 - val_accuracy: 0.9152\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2914 - accuracy: 0.8989 - val_loss: 0.1787 - val_accuracy: 0.9487\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2558 - accuracy: 0.9151 - val_loss: 0.1545 - val_accuracy: 0.9586\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2334 - accuracy: 0.9265 - val_loss: 0.1376 - val_accuracy: 0.9566\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2066 - accuracy: 0.9369 - val_loss: 0.1176 - val_accuracy: 0.9704\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1979 - accuracy: 0.9403 - val_loss: 0.1063 - val_accuracy: 0.9744\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1876 - accuracy: 0.9467 - val_loss: 0.1067 - val_accuracy: 0.9803\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1778 - accuracy: 0.9472 - val_loss: 0.0925 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1705 - accuracy: 0.9507 - val_loss: 0.0896 - val_accuracy: 0.9744\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1583 - accuracy: 0.9526 - val_loss: 0.0852 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1536 - accuracy: 0.9566 - val_loss: 0.0815 - val_accuracy: 0.9744\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 0.9576 - val_loss: 0.0855 - val_accuracy: 0.9665\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1463 - accuracy: 0.9581 - val_loss: 0.0772 - val_accuracy: 0.9763\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1451 - accuracy: 0.9571 - val_loss: 0.0788 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1433 - accuracy: 0.9595 - val_loss: 0.0763 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1359 - accuracy: 0.9581 - val_loss: 0.0876 - val_accuracy: 0.9645\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 0.9635 - val_loss: 0.0725 - val_accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1227 - accuracy: 0.9650 - val_loss: 0.0699 - val_accuracy: 0.9803\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1292 - accuracy: 0.9650 - val_loss: 0.0703 - val_accuracy: 0.9803\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1295 - accuracy: 0.9620 - val_loss: 0.0695 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1303 - accuracy: 0.9665 - val_loss: 0.0699 - val_accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1207 - accuracy: 0.9684 - val_loss: 0.0681 - val_accuracy: 0.9783\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1225 - accuracy: 0.9660 - val_loss: 0.0679 - val_accuracy: 0.9744\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1256 - accuracy: 0.9665 - val_loss: 0.0669 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1138 - accuracy: 0.9699 - val_loss: 0.0667 - val_accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1177 - accuracy: 0.9694 - val_loss: 0.0654 - val_accuracy: 0.9803\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1164 - accuracy: 0.9689 - val_loss: 0.0661 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1176 - accuracy: 0.9679 - val_loss: 0.0650 - val_accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1126 - accuracy: 0.9684 - val_loss: 0.0648 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1043 - accuracy: 0.9699 - val_loss: 0.0661 - val_accuracy: 0.9763\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.9694 - val_loss: 0.0708 - val_accuracy: 0.9763\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1122 - accuracy: 0.9679 - val_loss: 0.0640 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1038 - accuracy: 0.9694 - val_loss: 0.0639 - val_accuracy: 0.9803\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.9704 - val_loss: 0.0637 - val_accuracy: 0.9803\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9739 - val_loss: 0.0637 - val_accuracy: 0.9783\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1008 - accuracy: 0.9753 - val_loss: 0.0693 - val_accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1112 - accuracy: 0.9704 - val_loss: 0.0663 - val_accuracy: 0.9763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9729 - val_loss: 0.0619 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1014 - accuracy: 0.9724 - val_loss: 0.0633 - val_accuracy: 0.9763\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.9748 - val_loss: 0.0604 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.0631 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1045 - accuracy: 0.9743 - val_loss: 0.0643 - val_accuracy: 0.9763\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1057 - accuracy: 0.9709 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1043 - accuracy: 0.9748 - val_loss: 0.0606 - val_accuracy: 0.9763\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1047 - accuracy: 0.9719 - val_loss: 0.0578 - val_accuracy: 0.9842\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0969 - accuracy: 0.9768 - val_loss: 0.0577 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1051 - accuracy: 0.9709 - val_loss: 0.0587 - val_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0985 - accuracy: 0.9734 - val_loss: 0.0670 - val_accuracy: 0.9744\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1018 - accuracy: 0.9739 - val_loss: 0.0575 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0969 - accuracy: 0.9743 - val_loss: 0.0571 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0989 - accuracy: 0.9753 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0930 - accuracy: 0.9748 - val_loss: 0.0554 - val_accuracy: 0.9862\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0927 - accuracy: 0.9743 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0929 - accuracy: 0.9758 - val_loss: 0.0549 - val_accuracy: 0.9842\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0919 - accuracy: 0.9739 - val_loss: 0.0629 - val_accuracy: 0.9783\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0983 - accuracy: 0.9753 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0998 - accuracy: 0.9739 - val_loss: 0.0535 - val_accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.0600 - val_accuracy: 0.9783\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0950 - accuracy: 0.9719 - val_loss: 0.0645 - val_accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0975 - accuracy: 0.9739 - val_loss: 0.0575 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0992 - accuracy: 0.9734 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9753 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.9763 - val_loss: 0.0539 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0917 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0906 - accuracy: 0.9788 - val_loss: 0.0565 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0896 - accuracy: 0.9758 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0926 - accuracy: 0.9768 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0909 - accuracy: 0.9773 - val_loss: 0.0604 - val_accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9763 - val_loss: 0.0542 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0816 - accuracy: 0.9813 - val_loss: 0.0515 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9773 - val_loss: 0.0514 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0907 - accuracy: 0.9803 - val_loss: 0.0510 - val_accuracy: 0.9842\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0893 - accuracy: 0.9743 - val_loss: 0.0554 - val_accuracy: 0.9862\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9793 - val_loss: 0.0520 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 0.9763 - val_loss: 0.0510 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0866 - accuracy: 0.9768 - val_loss: 0.0505 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0863 - accuracy: 0.9778 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0835 - accuracy: 0.9788 - val_loss: 0.0505 - val_accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0828 - accuracy: 0.9803 - val_loss: 0.0501 - val_accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0821 - accuracy: 0.9798 - val_loss: 0.0500 - val_accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0827 - accuracy: 0.9798 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0903 - accuracy: 0.9758 - val_loss: 0.0501 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0881 - accuracy: 0.9788 - val_loss: 0.0504 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0805 - accuracy: 0.9798 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0827 - accuracy: 0.9763 - val_loss: 0.0509 - val_accuracy: 0.9862\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_76 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.6783 - accuracy: 0.5905 - val_loss: 0.6620 - val_accuracy: 0.6963\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6533 - accuracy: 0.6877 - val_loss: 0.6352 - val_accuracy: 0.7732\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6276 - accuracy: 0.7114 - val_loss: 0.5995 - val_accuracy: 0.8442\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5969 - accuracy: 0.7311 - val_loss: 0.5604 - val_accuracy: 0.8679\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5653 - accuracy: 0.7479 - val_loss: 0.5154 - val_accuracy: 0.8856\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5205 - accuracy: 0.7898 - val_loss: 0.4623 - val_accuracy: 0.8974\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4835 - accuracy: 0.8150 - val_loss: 0.4007 - val_accuracy: 0.8974\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4333 - accuracy: 0.8372 - val_loss: 0.3445 - val_accuracy: 0.9132\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8791 - val_loss: 0.2924 - val_accuracy: 0.9073\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3412 - accuracy: 0.8915 - val_loss: 0.2347 - val_accuracy: 0.9704\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2849 - accuracy: 0.9260 - val_loss: 0.1909 - val_accuracy: 0.9744\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2596 - accuracy: 0.9206 - val_loss: 0.1622 - val_accuracy: 0.9704\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.2246 - accuracy: 0.9457 - val_loss: 0.1469 - val_accuracy: 0.9763\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9408 - val_loss: 0.1216 - val_accuracy: 0.9783\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2028 - accuracy: 0.9428 - val_loss: 0.1152 - val_accuracy: 0.9763\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.9502 - val_loss: 0.1140 - val_accuracy: 0.9803\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1730 - accuracy: 0.9541 - val_loss: 0.0961 - val_accuracy: 0.9763\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1534 - accuracy: 0.9581 - val_loss: 0.0893 - val_accuracy: 0.9763\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1478 - accuracy: 0.9595 - val_loss: 0.0871 - val_accuracy: 0.9684\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1341 - accuracy: 0.9655 - val_loss: 0.0814 - val_accuracy: 0.9783\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1394 - accuracy: 0.9576 - val_loss: 0.0804 - val_accuracy: 0.9724\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1256 - accuracy: 0.9635 - val_loss: 0.0847 - val_accuracy: 0.9704\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1354 - accuracy: 0.9586 - val_loss: 0.0775 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1317 - accuracy: 0.9630 - val_loss: 0.0757 - val_accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1194 - accuracy: 0.9645 - val_loss: 0.0756 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1195 - accuracy: 0.9640 - val_loss: 0.0794 - val_accuracy: 0.9704\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1225 - accuracy: 0.9645 - val_loss: 0.0750 - val_accuracy: 0.9803\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.9669 - val_loss: 0.0704 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1191 - accuracy: 0.9630 - val_loss: 0.0734 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1074 - accuracy: 0.9694 - val_loss: 0.0685 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9684 - val_loss: 0.0680 - val_accuracy: 0.9803\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.9684 - val_loss: 0.0675 - val_accuracy: 0.9803\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1119 - accuracy: 0.9694 - val_loss: 0.0640 - val_accuracy: 0.9803\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1057 - accuracy: 0.9734 - val_loss: 0.0661 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1041 - accuracy: 0.9689 - val_loss: 0.0663 - val_accuracy: 0.9704\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1078 - accuracy: 0.9674 - val_loss: 0.0625 - val_accuracy: 0.9803\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1072 - accuracy: 0.9689 - val_loss: 0.0618 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1098 - accuracy: 0.9684 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9714 - val_loss: 0.0637 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9758 - val_loss: 0.0652 - val_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9709 - val_loss: 0.0592 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0981 - accuracy: 0.9743 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1054 - accuracy: 0.9743 - val_loss: 0.0610 - val_accuracy: 0.9842\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1015 - accuracy: 0.9729 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1031 - accuracy: 0.9719 - val_loss: 0.0543 - val_accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0930 - accuracy: 0.9734 - val_loss: 0.0549 - val_accuracy: 0.9822\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1065 - accuracy: 0.9684 - val_loss: 0.0662 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1153 - accuracy: 0.9739 - val_loss: 0.0642 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0994 - accuracy: 0.9743 - val_loss: 0.0586 - val_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1001 - accuracy: 0.9714 - val_loss: 0.0604 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0931 - accuracy: 0.9719 - val_loss: 0.0563 - val_accuracy: 0.9842\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1013 - accuracy: 0.9734 - val_loss: 0.0527 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0926 - accuracy: 0.9753 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0964 - accuracy: 0.9768 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0955 - accuracy: 0.9739 - val_loss: 0.0584 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 0.9788 - val_loss: 0.0513 - val_accuracy: 0.9862\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0916 - accuracy: 0.9739 - val_loss: 0.0537 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0966 - accuracy: 0.9768 - val_loss: 0.0594 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0946 - accuracy: 0.9758 - val_loss: 0.0542 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0947 - accuracy: 0.9768 - val_loss: 0.0515 - val_accuracy: 0.9842\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0919 - accuracy: 0.9743 - val_loss: 0.0557 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0881 - accuracy: 0.9788 - val_loss: 0.0532 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9743 - val_loss: 0.0517 - val_accuracy: 0.9842\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0902 - accuracy: 0.9773 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0865 - accuracy: 0.9763 - val_loss: 0.0526 - val_accuracy: 0.9862\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0827 - accuracy: 0.9793 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9758 - val_loss: 0.0508 - val_accuracy: 0.9862\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0925 - accuracy: 0.9748 - val_loss: 0.0503 - val_accuracy: 0.9862\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 0.0536 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0920 - accuracy: 0.9748 - val_loss: 0.0481 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0868 - accuracy: 0.9783 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9783 - val_loss: 0.0483 - val_accuracy: 0.9862\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0844 - accuracy: 0.9763 - val_loss: 0.0509 - val_accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9773 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9778 - val_loss: 0.0484 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9793 - val_loss: 0.0499 - val_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0875 - accuracy: 0.9763 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0861 - accuracy: 0.9783 - val_loss: 0.0517 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0790 - accuracy: 0.9793 - val_loss: 0.0486 - val_accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9813 - val_loss: 0.0503 - val_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0834 - accuracy: 0.9768 - val_loss: 0.0478 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0795 - accuracy: 0.9808 - val_loss: 0.0466 - val_accuracy: 0.9842\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0794 - accuracy: 0.9768 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0910 - accuracy: 0.9763 - val_loss: 0.0475 - val_accuracy: 0.9862\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0850 - accuracy: 0.9793 - val_loss: 0.0497 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0788 - accuracy: 0.9778 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0899 - accuracy: 0.9753 - val_loss: 0.0549 - val_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0818 - accuracy: 0.9778 - val_loss: 0.0520 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0887 - accuracy: 0.9743 - val_loss: 0.0463 - val_accuracy: 0.9882\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0891 - accuracy: 0.9768 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0851 - accuracy: 0.9788 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9763 - val_loss: 0.0460 - val_accuracy: 0.9882\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9788 - val_loss: 0.0552 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0806 - accuracy: 0.9788 - val_loss: 0.0492 - val_accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0770 - accuracy: 0.9808 - val_loss: 0.0438 - val_accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0837 - accuracy: 0.9778 - val_loss: 0.0479 - val_accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0703 - accuracy: 0.9813 - val_loss: 0.0435 - val_accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0825 - accuracy: 0.9788 - val_loss: 0.0508 - val_accuracy: 0.9842\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0866 - accuracy: 0.9783 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9798 - val_loss: 0.0443 - val_accuracy: 0.9862\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 27ms/step - loss: 0.6907 - accuracy: 0.5047 - val_loss: 0.6784 - val_accuracy: 0.4911\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6718 - accuracy: 0.6295 - val_loss: 0.6545 - val_accuracy: 0.8462\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6490 - accuracy: 0.7262 - val_loss: 0.6267 - val_accuracy: 0.8639\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6219 - accuracy: 0.7509 - val_loss: 0.5876 - val_accuracy: 0.8718\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5863 - accuracy: 0.7711 - val_loss: 0.5359 - val_accuracy: 0.8895\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5423 - accuracy: 0.7967 - val_loss: 0.4850 - val_accuracy: 0.9034\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5052 - accuracy: 0.8081 - val_loss: 0.4397 - val_accuracy: 0.9152\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4733 - accuracy: 0.8268 - val_loss: 0.3878 - val_accuracy: 0.9132\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.4309 - accuracy: 0.8500 - val_loss: 0.3471 - val_accuracy: 0.9152\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.8663 - val_loss: 0.3049 - val_accuracy: 0.9270\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3513 - accuracy: 0.8846 - val_loss: 0.2497 - val_accuracy: 0.9310\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3053 - accuracy: 0.8964 - val_loss: 0.2036 - val_accuracy: 0.9467\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2791 - accuracy: 0.9068 - val_loss: 0.1709 - val_accuracy: 0.9606\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2420 - accuracy: 0.9304 - val_loss: 0.1468 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9275 - val_loss: 0.1364 - val_accuracy: 0.9507\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1995 - accuracy: 0.9403 - val_loss: 0.1153 - val_accuracy: 0.9684\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9443 - val_loss: 0.1102 - val_accuracy: 0.9566\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1779 - accuracy: 0.9413 - val_loss: 0.1195 - val_accuracy: 0.9507\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1705 - accuracy: 0.9457 - val_loss: 0.0997 - val_accuracy: 0.9625\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.0936 - val_accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1459 - accuracy: 0.9556 - val_loss: 0.0889 - val_accuracy: 0.9684\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1469 - accuracy: 0.9566 - val_loss: 0.0851 - val_accuracy: 0.9704\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1431 - accuracy: 0.9561 - val_loss: 0.0845 - val_accuracy: 0.9704\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1460 - accuracy: 0.9551 - val_loss: 0.0801 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1363 - accuracy: 0.9600 - val_loss: 0.0808 - val_accuracy: 0.9803\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1252 - accuracy: 0.9615 - val_loss: 0.0764 - val_accuracy: 0.9744\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1309 - accuracy: 0.9615 - val_loss: 0.0753 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1327 - accuracy: 0.9531 - val_loss: 0.0746 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1337 - accuracy: 0.9615 - val_loss: 0.0747 - val_accuracy: 0.9744\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1278 - accuracy: 0.9650 - val_loss: 0.0751 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1271 - accuracy: 0.9630 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1186 - accuracy: 0.9625 - val_loss: 0.0720 - val_accuracy: 0.9763\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1199 - accuracy: 0.9620 - val_loss: 0.0740 - val_accuracy: 0.9803\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1253 - accuracy: 0.9640 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1224 - accuracy: 0.9669 - val_loss: 0.0734 - val_accuracy: 0.9724\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1131 - accuracy: 0.9660 - val_loss: 0.0700 - val_accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1134 - accuracy: 0.9674 - val_loss: 0.0683 - val_accuracy: 0.9783\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1205 - accuracy: 0.9625 - val_loss: 0.0681 - val_accuracy: 0.9744\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9610 - val_loss: 0.0676 - val_accuracy: 0.9783\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1150 - accuracy: 0.9679 - val_loss: 0.0677 - val_accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9689 - val_loss: 0.0652 - val_accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9689 - val_loss: 0.0648 - val_accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1128 - accuracy: 0.9640 - val_loss: 0.0652 - val_accuracy: 0.9783\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1077 - accuracy: 0.9694 - val_loss: 0.0646 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1077 - accuracy: 0.9694 - val_loss: 0.0640 - val_accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9689 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1087 - accuracy: 0.9709 - val_loss: 0.0616 - val_accuracy: 0.9744\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 0.9704 - val_loss: 0.0644 - val_accuracy: 0.9783\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1060 - accuracy: 0.9660 - val_loss: 0.0603 - val_accuracy: 0.9763\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1078 - accuracy: 0.9694 - val_loss: 0.0620 - val_accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1039 - accuracy: 0.9739 - val_loss: 0.0601 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1072 - accuracy: 0.9709 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1087 - accuracy: 0.9694 - val_loss: 0.0597 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1031 - accuracy: 0.9709 - val_loss: 0.0617 - val_accuracy: 0.9783\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1054 - accuracy: 0.9709 - val_loss: 0.0628 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1065 - accuracy: 0.9684 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1004 - accuracy: 0.9709 - val_loss: 0.0592 - val_accuracy: 0.9803\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9724 - val_loss: 0.0589 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1014 - accuracy: 0.9679 - val_loss: 0.0580 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1029 - accuracy: 0.9719 - val_loss: 0.0590 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1002 - accuracy: 0.9699 - val_loss: 0.0576 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0996 - accuracy: 0.9704 - val_loss: 0.0566 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0976 - accuracy: 0.9719 - val_loss: 0.0584 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0950 - accuracy: 0.9748 - val_loss: 0.0570 - val_accuracy: 0.9822\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1033 - accuracy: 0.9714 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0951 - accuracy: 0.9714 - val_loss: 0.0567 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0978 - accuracy: 0.9724 - val_loss: 0.0594 - val_accuracy: 0.9783\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0915 - accuracy: 0.9768 - val_loss: 0.0558 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0945 - accuracy: 0.9734 - val_loss: 0.0549 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1000 - accuracy: 0.9719 - val_loss: 0.0567 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1002 - accuracy: 0.9748 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9719 - val_loss: 0.0550 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0968 - accuracy: 0.9709 - val_loss: 0.0566 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1036 - accuracy: 0.9689 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.0574 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0942 - accuracy: 0.9739 - val_loss: 0.0637 - val_accuracy: 0.9783\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1007 - accuracy: 0.9694 - val_loss: 0.0564 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0944 - accuracy: 0.9709 - val_loss: 0.0558 - val_accuracy: 0.9822\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 0.9773 - val_loss: 0.0591 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0913 - accuracy: 0.9729 - val_loss: 0.0568 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0906 - accuracy: 0.9724 - val_loss: 0.0556 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0922 - accuracy: 0.9753 - val_loss: 0.0619 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9778 - val_loss: 0.0568 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0857 - accuracy: 0.9798 - val_loss: 0.0546 - val_accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0954 - accuracy: 0.9768 - val_loss: 0.0548 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 0.9778 - val_loss: 0.0563 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1001 - accuracy: 0.9704 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 0.9724 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.9758 - val_loss: 0.0570 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0977 - accuracy: 0.9763 - val_loss: 0.0556 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0878 - accuracy: 0.9739 - val_loss: 0.0540 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0929 - accuracy: 0.9753 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0940 - accuracy: 0.9768 - val_loss: 0.0565 - val_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9778 - val_loss: 0.0537 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9768 - val_loss: 0.0553 - val_accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9748 - val_loss: 0.0555 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0900 - accuracy: 0.9768 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0865 - accuracy: 0.9748 - val_loss: 0.0521 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0914 - accuracy: 0.9763 - val_loss: 0.0521 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0880 - accuracy: 0.9758 - val_loss: 0.0546 - val_accuracy: 0.9842\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 0.6780 - accuracy: 0.5831 - val_loss: 0.6466 - val_accuracy: 0.7929\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6414 - accuracy: 0.7040 - val_loss: 0.6131 - val_accuracy: 0.8284\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6139 - accuracy: 0.7375 - val_loss: 0.5842 - val_accuracy: 0.8264\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5976 - accuracy: 0.7528 - val_loss: 0.5530 - val_accuracy: 0.8323\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5687 - accuracy: 0.7637 - val_loss: 0.5217 - val_accuracy: 0.8698\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5355 - accuracy: 0.7874 - val_loss: 0.4832 - val_accuracy: 0.8698\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5103 - accuracy: 0.7977 - val_loss: 0.4429 - val_accuracy: 0.8876\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.8160 - val_loss: 0.4067 - val_accuracy: 0.8797\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4416 - accuracy: 0.8328 - val_loss: 0.3647 - val_accuracy: 0.9014\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4252 - accuracy: 0.8416 - val_loss: 0.3330 - val_accuracy: 0.8895\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3952 - accuracy: 0.8584 - val_loss: 0.2976 - val_accuracy: 0.9132\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8806 - val_loss: 0.2663 - val_accuracy: 0.9132\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.8806 - val_loss: 0.2341 - val_accuracy: 0.9132\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3042 - accuracy: 0.8910 - val_loss: 0.2046 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2737 - accuracy: 0.9122 - val_loss: 0.1712 - val_accuracy: 0.9448\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2378 - accuracy: 0.9196 - val_loss: 0.1469 - val_accuracy: 0.9684\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2220 - accuracy: 0.9329 - val_loss: 0.1246 - val_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1933 - accuracy: 0.9447 - val_loss: 0.1169 - val_accuracy: 0.9822\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1888 - accuracy: 0.9452 - val_loss: 0.1002 - val_accuracy: 0.9744\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.9521 - val_loss: 0.0931 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1570 - accuracy: 0.9576 - val_loss: 0.0894 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.9576 - val_loss: 0.0824 - val_accuracy: 0.9763\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1496 - accuracy: 0.9635 - val_loss: 0.0803 - val_accuracy: 0.9803\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1451 - accuracy: 0.9536 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1499 - accuracy: 0.9630 - val_loss: 0.0763 - val_accuracy: 0.9763\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1376 - accuracy: 0.9600 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1350 - accuracy: 0.9650 - val_loss: 0.0720 - val_accuracy: 0.9763\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1383 - accuracy: 0.9615 - val_loss: 0.0790 - val_accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1295 - accuracy: 0.9655 - val_loss: 0.0695 - val_accuracy: 0.9763\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1240 - accuracy: 0.9679 - val_loss: 0.0686 - val_accuracy: 0.9783\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1242 - accuracy: 0.9699 - val_loss: 0.0678 - val_accuracy: 0.9783\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1219 - accuracy: 0.9679 - val_loss: 0.0731 - val_accuracy: 0.9744\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1234 - accuracy: 0.9660 - val_loss: 0.0700 - val_accuracy: 0.9763\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1240 - accuracy: 0.9719 - val_loss: 0.0712 - val_accuracy: 0.9763\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1174 - accuracy: 0.9674 - val_loss: 0.0676 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1137 - accuracy: 0.9729 - val_loss: 0.0678 - val_accuracy: 0.9763\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1135 - accuracy: 0.9684 - val_loss: 0.0639 - val_accuracy: 0.9783\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1148 - accuracy: 0.9669 - val_loss: 0.0790 - val_accuracy: 0.9803\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1181 - accuracy: 0.9674 - val_loss: 0.0687 - val_accuracy: 0.9763\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1241 - accuracy: 0.9684 - val_loss: 0.0622 - val_accuracy: 0.9783\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1168 - accuracy: 0.9709 - val_loss: 0.0726 - val_accuracy: 0.9763\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1157 - accuracy: 0.9694 - val_loss: 0.0666 - val_accuracy: 0.9763\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1041 - accuracy: 0.9714 - val_loss: 0.0597 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9748 - val_loss: 0.0594 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1036 - accuracy: 0.9743 - val_loss: 0.0583 - val_accuracy: 0.9803\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9709 - val_loss: 0.0579 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0978 - accuracy: 0.9743 - val_loss: 0.0591 - val_accuracy: 0.9783\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1086 - accuracy: 0.9724 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.9739 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 0.9763 - val_loss: 0.0573 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1054 - accuracy: 0.9763 - val_loss: 0.0580 - val_accuracy: 0.9803\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1037 - accuracy: 0.9734 - val_loss: 0.0570 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1096 - accuracy: 0.9748 - val_loss: 0.0621 - val_accuracy: 0.9763\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1011 - accuracy: 0.9753 - val_loss: 0.0587 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 0.9748 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.0642 - val_accuracy: 0.9783\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1018 - accuracy: 0.9729 - val_loss: 0.0569 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1006 - accuracy: 0.9729 - val_loss: 0.0558 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 0.0557 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9793 - val_loss: 0.0552 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0981 - accuracy: 0.9763 - val_loss: 0.0541 - val_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1008 - accuracy: 0.9743 - val_loss: 0.0540 - val_accuracy: 0.9842\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0892 - accuracy: 0.9783 - val_loss: 0.0534 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9739 - val_loss: 0.0550 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0926 - accuracy: 0.9778 - val_loss: 0.0529 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0896 - accuracy: 0.9773 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1003 - accuracy: 0.9778 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0900 - accuracy: 0.9778 - val_loss: 0.0512 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0944 - accuracy: 0.9773 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0944 - accuracy: 0.9763 - val_loss: 0.0521 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0914 - accuracy: 0.9748 - val_loss: 0.0535 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0911 - accuracy: 0.9798 - val_loss: 0.0518 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9773 - val_loss: 0.0541 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0886 - accuracy: 0.9793 - val_loss: 0.0501 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0985 - accuracy: 0.9763 - val_loss: 0.0549 - val_accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 0.9748 - val_loss: 0.0621 - val_accuracy: 0.9783\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9778 - val_loss: 0.0505 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0846 - accuracy: 0.9783 - val_loss: 0.0486 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0916 - accuracy: 0.9788 - val_loss: 0.0511 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9758 - val_loss: 0.0565 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0992 - accuracy: 0.9753 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0960 - accuracy: 0.9778 - val_loss: 0.0504 - val_accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.9788 - val_loss: 0.0490 - val_accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0841 - accuracy: 0.9808 - val_loss: 0.0481 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0898 - accuracy: 0.9798 - val_loss: 0.0479 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0895 - accuracy: 0.9778 - val_loss: 0.0502 - val_accuracy: 0.9842\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0876 - accuracy: 0.9798 - val_loss: 0.0521 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0857 - accuracy: 0.9778 - val_loss: 0.0483 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0858 - accuracy: 0.9822 - val_loss: 0.0495 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0850 - accuracy: 0.9798 - val_loss: 0.0508 - val_accuracy: 0.9842\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 0.9783 - val_loss: 0.0481 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0826 - accuracy: 0.9798 - val_loss: 0.0480 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.9793 - val_loss: 0.0478 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0810 - accuracy: 0.9813 - val_loss: 0.0471 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0797 - accuracy: 0.9773 - val_loss: 0.0465 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.9793 - val_loss: 0.0489 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.9808 - val_loss: 0.0472 - val_accuracy: 0.9822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0826 - accuracy: 0.9788 - val_loss: 0.0481 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0819 - accuracy: 0.9793 - val_loss: 0.0525 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0862 - accuracy: 0.9783 - val_loss: 0.0466 - val_accuracy: 0.9842\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 25ms/step - loss: 0.6962 - accuracy: 0.5037 - val_loss: 0.6879 - val_accuracy: 0.5168\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.5402 - val_loss: 0.6777 - val_accuracy: 0.5740\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6719 - accuracy: 0.5767 - val_loss: 0.6604 - val_accuracy: 0.6312\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6537 - accuracy: 0.5950 - val_loss: 0.6373 - val_accuracy: 0.6568\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6315 - accuracy: 0.6374 - val_loss: 0.6121 - val_accuracy: 0.6884\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.6354 - val_loss: 0.5808 - val_accuracy: 0.7692\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5748 - accuracy: 0.7282 - val_loss: 0.5429 - val_accuracy: 0.7535\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.5454 - accuracy: 0.7573 - val_loss: 0.5054 - val_accuracy: 0.8245\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5152 - accuracy: 0.7972 - val_loss: 0.4682 - val_accuracy: 0.8836\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4802 - accuracy: 0.8342 - val_loss: 0.4278 - val_accuracy: 0.8994\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4498 - accuracy: 0.8535 - val_loss: 0.3948 - val_accuracy: 0.9053\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.4135 - accuracy: 0.8772 - val_loss: 0.3555 - val_accuracy: 0.9152\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.8762 - val_loss: 0.3204 - val_accuracy: 0.9270\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.3609 - accuracy: 0.8816 - val_loss: 0.2885 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3498 - accuracy: 0.8806 - val_loss: 0.2754 - val_accuracy: 0.9093\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3254 - accuracy: 0.8865 - val_loss: 0.2485 - val_accuracy: 0.9191\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.9053 - val_loss: 0.2079 - val_accuracy: 0.9527\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2796 - accuracy: 0.9087 - val_loss: 0.1853 - val_accuracy: 0.9684\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2467 - accuracy: 0.9309 - val_loss: 0.1675 - val_accuracy: 0.9684\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2370 - accuracy: 0.9280 - val_loss: 0.1534 - val_accuracy: 0.9684\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2257 - accuracy: 0.9418 - val_loss: 0.1459 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2208 - accuracy: 0.9354 - val_loss: 0.1350 - val_accuracy: 0.9684\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 0.9487 - val_loss: 0.1262 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2000 - accuracy: 0.9487 - val_loss: 0.1202 - val_accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1947 - accuracy: 0.9467 - val_loss: 0.1160 - val_accuracy: 0.9744\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1786 - accuracy: 0.9546 - val_loss: 0.1099 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1877 - accuracy: 0.9531 - val_loss: 0.1070 - val_accuracy: 0.9744\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1780 - accuracy: 0.9546 - val_loss: 0.1044 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1758 - accuracy: 0.9576 - val_loss: 0.1006 - val_accuracy: 0.9783\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1719 - accuracy: 0.9635 - val_loss: 0.1025 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1722 - accuracy: 0.9615 - val_loss: 0.0962 - val_accuracy: 0.9763\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1692 - accuracy: 0.9556 - val_loss: 0.0939 - val_accuracy: 0.9763\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1593 - accuracy: 0.9645 - val_loss: 0.0928 - val_accuracy: 0.9783\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1662 - accuracy: 0.9620 - val_loss: 0.0918 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1592 - accuracy: 0.9576 - val_loss: 0.0908 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1616 - accuracy: 0.9620 - val_loss: 0.0874 - val_accuracy: 0.9822\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1560 - accuracy: 0.9610 - val_loss: 0.0871 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1538 - accuracy: 0.9655 - val_loss: 0.0858 - val_accuracy: 0.9763\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1484 - accuracy: 0.9669 - val_loss: 0.0825 - val_accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1498 - accuracy: 0.9669 - val_loss: 0.0816 - val_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1475 - accuracy: 0.9684 - val_loss: 0.0821 - val_accuracy: 0.9783\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1538 - accuracy: 0.9674 - val_loss: 0.0857 - val_accuracy: 0.9665\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1538 - accuracy: 0.9669 - val_loss: 0.0840 - val_accuracy: 0.9744\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1358 - accuracy: 0.9694 - val_loss: 0.0760 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1440 - accuracy: 0.9679 - val_loss: 0.0752 - val_accuracy: 0.9842\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1445 - accuracy: 0.9674 - val_loss: 0.0752 - val_accuracy: 0.9783\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1542 - accuracy: 0.9615 - val_loss: 0.0758 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1419 - accuracy: 0.9699 - val_loss: 0.0796 - val_accuracy: 0.9744\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1402 - accuracy: 0.9699 - val_loss: 0.0759 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1351 - accuracy: 0.9689 - val_loss: 0.0803 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1533 - accuracy: 0.9645 - val_loss: 0.0742 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1424 - accuracy: 0.9665 - val_loss: 0.0730 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1344 - accuracy: 0.9729 - val_loss: 0.0703 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1307 - accuracy: 0.9714 - val_loss: 0.0698 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1350 - accuracy: 0.9709 - val_loss: 0.0670 - val_accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1303 - accuracy: 0.9729 - val_loss: 0.0685 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1309 - accuracy: 0.9714 - val_loss: 0.0699 - val_accuracy: 0.9763\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1334 - accuracy: 0.9709 - val_loss: 0.0657 - val_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.9724 - val_loss: 0.0710 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1286 - accuracy: 0.9719 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1326 - accuracy: 0.9729 - val_loss: 0.0663 - val_accuracy: 0.9763\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1239 - accuracy: 0.9739 - val_loss: 0.0704 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1286 - accuracy: 0.9719 - val_loss: 0.0652 - val_accuracy: 0.9763\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1351 - accuracy: 0.9734 - val_loss: 0.0634 - val_accuracy: 0.9783\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1235 - accuracy: 0.9724 - val_loss: 0.0671 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1212 - accuracy: 0.9719 - val_loss: 0.0610 - val_accuracy: 0.9783\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1247 - accuracy: 0.9704 - val_loss: 0.0626 - val_accuracy: 0.9763\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1251 - accuracy: 0.9694 - val_loss: 0.0620 - val_accuracy: 0.9763\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9724 - val_loss: 0.0614 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1123 - accuracy: 0.9773 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1231 - accuracy: 0.9729 - val_loss: 0.0617 - val_accuracy: 0.9803\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1103 - accuracy: 0.9724 - val_loss: 0.0614 - val_accuracy: 0.9842\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1259 - accuracy: 0.9734 - val_loss: 0.0657 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9753 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1225 - accuracy: 0.9729 - val_loss: 0.0608 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1179 - accuracy: 0.9773 - val_loss: 0.0585 - val_accuracy: 0.9803\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1203 - accuracy: 0.9753 - val_loss: 0.0578 - val_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1097 - accuracy: 0.9783 - val_loss: 0.0554 - val_accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1187 - accuracy: 0.9739 - val_loss: 0.0551 - val_accuracy: 0.9803\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1168 - accuracy: 0.9763 - val_loss: 0.0622 - val_accuracy: 0.9803\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1148 - accuracy: 0.9748 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1081 - accuracy: 0.9758 - val_loss: 0.0565 - val_accuracy: 0.9803\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1111 - accuracy: 0.9773 - val_loss: 0.0557 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1129 - accuracy: 0.9758 - val_loss: 0.0563 - val_accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 0.9763 - val_loss: 0.0575 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.9758 - val_loss: 0.0572 - val_accuracy: 0.9763\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1144 - accuracy: 0.9743 - val_loss: 0.0564 - val_accuracy: 0.9783\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1100 - accuracy: 0.9788 - val_loss: 0.0651 - val_accuracy: 0.9803\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1148 - accuracy: 0.9753 - val_loss: 0.0595 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1188 - accuracy: 0.9724 - val_loss: 0.0590 - val_accuracy: 0.9763\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1134 - accuracy: 0.9783 - val_loss: 0.0549 - val_accuracy: 0.9803\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9753 - val_loss: 0.0669 - val_accuracy: 0.9803\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1154 - accuracy: 0.9753 - val_loss: 0.0575 - val_accuracy: 0.9783\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1066 - accuracy: 0.9778 - val_loss: 0.0543 - val_accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1076 - accuracy: 0.9758 - val_loss: 0.0603 - val_accuracy: 0.9822\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1113 - accuracy: 0.9743 - val_loss: 0.0541 - val_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1097 - accuracy: 0.9768 - val_loss: 0.0526 - val_accuracy: 0.9803\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1005 - accuracy: 0.9763 - val_loss: 0.0651 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9753 - val_loss: 0.0542 - val_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1069 - accuracy: 0.9783 - val_loss: 0.0554 - val_accuracy: 0.9803\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_168 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 30ms/step - loss: 0.6924 - accuracy: 0.5298 - val_loss: 0.6793 - val_accuracy: 0.6864\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6713 - accuracy: 0.6127 - val_loss: 0.6401 - val_accuracy: 0.8600\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.6337 - accuracy: 0.7124 - val_loss: 0.5821 - val_accuracy: 0.8876\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5783 - accuracy: 0.7869 - val_loss: 0.5213 - val_accuracy: 0.8915\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.7889 - val_loss: 0.4592 - val_accuracy: 0.9034\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.8239 - val_loss: 0.3967 - val_accuracy: 0.9014\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.8402 - val_loss: 0.3422 - val_accuracy: 0.9152\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3851 - accuracy: 0.8638 - val_loss: 0.2895 - val_accuracy: 0.9270\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3473 - accuracy: 0.8791 - val_loss: 0.2438 - val_accuracy: 0.9448\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.3010 - accuracy: 0.9043 - val_loss: 0.2018 - val_accuracy: 0.9527\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.9038 - val_loss: 0.1719 - val_accuracy: 0.9625\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2377 - accuracy: 0.9285 - val_loss: 0.1502 - val_accuracy: 0.9684\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2217 - accuracy: 0.9240 - val_loss: 0.1398 - val_accuracy: 0.9684\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2080 - accuracy: 0.9334 - val_loss: 0.1238 - val_accuracy: 0.9586\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1979 - accuracy: 0.9393 - val_loss: 0.1222 - val_accuracy: 0.9566\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1846 - accuracy: 0.9388 - val_loss: 0.1074 - val_accuracy: 0.9606\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1704 - accuracy: 0.9492 - val_loss: 0.0996 - val_accuracy: 0.9704\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1652 - accuracy: 0.9502 - val_loss: 0.0947 - val_accuracy: 0.9684\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1710 - accuracy: 0.9482 - val_loss: 0.0953 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1621 - accuracy: 0.9487 - val_loss: 0.0896 - val_accuracy: 0.9665\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1521 - accuracy: 0.9521 - val_loss: 0.0840 - val_accuracy: 0.9744\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1450 - accuracy: 0.9591 - val_loss: 0.0860 - val_accuracy: 0.9665\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1484 - accuracy: 0.9561 - val_loss: 0.0790 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1360 - accuracy: 0.9610 - val_loss: 0.0755 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1243 - accuracy: 0.9605 - val_loss: 0.0733 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1347 - accuracy: 0.9630 - val_loss: 0.0729 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1200 - accuracy: 0.9655 - val_loss: 0.0718 - val_accuracy: 0.9803\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.9665 - val_loss: 0.0742 - val_accuracy: 0.9704\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1346 - accuracy: 0.9630 - val_loss: 0.0705 - val_accuracy: 0.9763\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1302 - accuracy: 0.9650 - val_loss: 0.0713 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1194 - accuracy: 0.9655 - val_loss: 0.0705 - val_accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1234 - accuracy: 0.9669 - val_loss: 0.0706 - val_accuracy: 0.9783\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1224 - accuracy: 0.9679 - val_loss: 0.0703 - val_accuracy: 0.9822\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1232 - accuracy: 0.9669 - val_loss: 0.0671 - val_accuracy: 0.9803\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1264 - accuracy: 0.9630 - val_loss: 0.0671 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1252 - accuracy: 0.9679 - val_loss: 0.0739 - val_accuracy: 0.9665\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1209 - accuracy: 0.9665 - val_loss: 0.0916 - val_accuracy: 0.9645\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1322 - accuracy: 0.9620 - val_loss: 0.0654 - val_accuracy: 0.9763\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1166 - accuracy: 0.9694 - val_loss: 0.0643 - val_accuracy: 0.9803\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1107 - accuracy: 0.9743 - val_loss: 0.0653 - val_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1190 - accuracy: 0.9709 - val_loss: 0.0652 - val_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1111 - accuracy: 0.9724 - val_loss: 0.0626 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 0.9734 - val_loss: 0.0614 - val_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1065 - accuracy: 0.9709 - val_loss: 0.0628 - val_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1145 - accuracy: 0.9714 - val_loss: 0.0602 - val_accuracy: 0.9783\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1129 - accuracy: 0.9709 - val_loss: 0.0631 - val_accuracy: 0.9724\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1080 - accuracy: 0.9729 - val_loss: 0.0610 - val_accuracy: 0.9822\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1091 - accuracy: 0.9743 - val_loss: 0.0617 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1012 - accuracy: 0.9758 - val_loss: 0.0619 - val_accuracy: 0.9763\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0993 - accuracy: 0.9729 - val_loss: 0.0610 - val_accuracy: 0.9744\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1095 - accuracy: 0.9743 - val_loss: 0.0616 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0974 - accuracy: 0.9729 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1043 - accuracy: 0.9714 - val_loss: 0.0601 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9739 - val_loss: 0.0602 - val_accuracy: 0.9763\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1024 - accuracy: 0.9734 - val_loss: 0.0603 - val_accuracy: 0.9842\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.0598 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1109 - accuracy: 0.9714 - val_loss: 0.0596 - val_accuracy: 0.9842\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1024 - accuracy: 0.9748 - val_loss: 0.0684 - val_accuracy: 0.9783\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0982 - accuracy: 0.9734 - val_loss: 0.0574 - val_accuracy: 0.9842\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1004 - accuracy: 0.9758 - val_loss: 0.0594 - val_accuracy: 0.9763\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0912 - accuracy: 0.9758 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0938 - accuracy: 0.9798 - val_loss: 0.0545 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0859 - accuracy: 0.9793 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1018 - accuracy: 0.9768 - val_loss: 0.0575 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0927 - accuracy: 0.9798 - val_loss: 0.0534 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0911 - accuracy: 0.9783 - val_loss: 0.0594 - val_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0957 - accuracy: 0.9773 - val_loss: 0.0542 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0856 - accuracy: 0.9768 - val_loss: 0.0546 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0873 - accuracy: 0.9783 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 0.9778 - val_loss: 0.0556 - val_accuracy: 0.9803\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0886 - accuracy: 0.9743 - val_loss: 0.0522 - val_accuracy: 0.9803\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9778 - val_loss: 0.0514 - val_accuracy: 0.9803\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0926 - accuracy: 0.9763 - val_loss: 0.0499 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0851 - accuracy: 0.9783 - val_loss: 0.0511 - val_accuracy: 0.9842\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9788 - val_loss: 0.0501 - val_accuracy: 0.9862\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9783 - val_loss: 0.0501 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0936 - accuracy: 0.9778 - val_loss: 0.0510 - val_accuracy: 0.9842\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0880 - accuracy: 0.9803 - val_loss: 0.0504 - val_accuracy: 0.9842\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0907 - accuracy: 0.9798 - val_loss: 0.0608 - val_accuracy: 0.9803\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0905 - accuracy: 0.9773 - val_loss: 0.0490 - val_accuracy: 0.9842\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0846 - accuracy: 0.9808 - val_loss: 0.0510 - val_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0997 - accuracy: 0.9763 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0873 - accuracy: 0.9793 - val_loss: 0.0540 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0769 - accuracy: 0.9813 - val_loss: 0.0541 - val_accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0833 - accuracy: 0.9808 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0849 - accuracy: 0.9808 - val_loss: 0.0552 - val_accuracy: 0.9803\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0894 - accuracy: 0.9793 - val_loss: 0.0527 - val_accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0839 - accuracy: 0.9768 - val_loss: 0.0483 - val_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0863 - accuracy: 0.9793 - val_loss: 0.0497 - val_accuracy: 0.9822\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0830 - accuracy: 0.9832 - val_loss: 0.0523 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0825 - accuracy: 0.9803 - val_loss: 0.0480 - val_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0855 - accuracy: 0.9798 - val_loss: 0.0533 - val_accuracy: 0.9803\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0943 - accuracy: 0.9773 - val_loss: 0.0755 - val_accuracy: 0.9724\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1005 - accuracy: 0.9758 - val_loss: 0.0592 - val_accuracy: 0.9803\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0853 - accuracy: 0.9822 - val_loss: 0.0452 - val_accuracy: 0.9882\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0896 - accuracy: 0.9793 - val_loss: 0.0579 - val_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.9813 - val_loss: 0.0469 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0839 - accuracy: 0.9773 - val_loss: 0.0499 - val_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0801 - accuracy: 0.9788 - val_loss: 0.0471 - val_accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0784 - accuracy: 0.9813 - val_loss: 0.0565 - val_accuracy: 0.9803\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_86 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_87 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.6859 - accuracy: 0.5555 - val_loss: 0.6706 - val_accuracy: 0.7436\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.6683 - accuracy: 0.6201 - val_loss: 0.6491 - val_accuracy: 0.8304\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6461 - accuracy: 0.6862 - val_loss: 0.6230 - val_accuracy: 0.8757\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6175 - accuracy: 0.7208 - val_loss: 0.5854 - val_accuracy: 0.8205\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5896 - accuracy: 0.7060 - val_loss: 0.5470 - val_accuracy: 0.8974\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5577 - accuracy: 0.7765 - val_loss: 0.5008 - val_accuracy: 0.8994\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5223 - accuracy: 0.7711 - val_loss: 0.4560 - val_accuracy: 0.9073\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4756 - accuracy: 0.8234 - val_loss: 0.4082 - val_accuracy: 0.9053\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4470 - accuracy: 0.8308 - val_loss: 0.3574 - val_accuracy: 0.9191\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.4148 - accuracy: 0.8352 - val_loss: 0.3287 - val_accuracy: 0.9152\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3776 - accuracy: 0.8619 - val_loss: 0.2865 - val_accuracy: 0.9250\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3581 - accuracy: 0.8801 - val_loss: 0.2536 - val_accuracy: 0.9231\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3252 - accuracy: 0.8860 - val_loss: 0.2228 - val_accuracy: 0.9467\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2922 - accuracy: 0.9058 - val_loss: 0.1979 - val_accuracy: 0.9448\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2792 - accuracy: 0.9117 - val_loss: 0.1742 - val_accuracy: 0.9645\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2550 - accuracy: 0.9245 - val_loss: 0.1589 - val_accuracy: 0.9645\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2413 - accuracy: 0.9240 - val_loss: 0.1448 - val_accuracy: 0.9665\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2137 - accuracy: 0.9324 - val_loss: 0.1249 - val_accuracy: 0.9744\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2026 - accuracy: 0.9359 - val_loss: 0.1147 - val_accuracy: 0.9744\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1947 - accuracy: 0.9408 - val_loss: 0.1072 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1927 - accuracy: 0.9383 - val_loss: 0.1064 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1782 - accuracy: 0.9482 - val_loss: 0.1016 - val_accuracy: 0.9783\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1731 - accuracy: 0.9517 - val_loss: 0.0939 - val_accuracy: 0.9783\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1630 - accuracy: 0.9521 - val_loss: 0.0929 - val_accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1667 - accuracy: 0.9526 - val_loss: 0.0886 - val_accuracy: 0.9763\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 0.9576 - val_loss: 0.0824 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1479 - accuracy: 0.9591 - val_loss: 0.0794 - val_accuracy: 0.9783\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1449 - accuracy: 0.9605 - val_loss: 0.0818 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1442 - accuracy: 0.9595 - val_loss: 0.0787 - val_accuracy: 0.9763\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1383 - accuracy: 0.9576 - val_loss: 0.0763 - val_accuracy: 0.9744\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1308 - accuracy: 0.9625 - val_loss: 0.0758 - val_accuracy: 0.9822\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.1323 - accuracy: 0.9620 - val_loss: 0.0719 - val_accuracy: 0.9803\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1256 - accuracy: 0.9640 - val_loss: 0.0716 - val_accuracy: 0.9763\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1361 - accuracy: 0.9620 - val_loss: 0.0685 - val_accuracy: 0.9803\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1207 - accuracy: 0.9669 - val_loss: 0.0680 - val_accuracy: 0.9822\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1175 - accuracy: 0.9665 - val_loss: 0.0640 - val_accuracy: 0.9783\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 0.9704 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.0655 - val_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1172 - accuracy: 0.9669 - val_loss: 0.0618 - val_accuracy: 0.9803\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9640 - val_loss: 0.0632 - val_accuracy: 0.9803\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1179 - accuracy: 0.9669 - val_loss: 0.0612 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1206 - accuracy: 0.9699 - val_loss: 0.0628 - val_accuracy: 0.9783\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1259 - accuracy: 0.9635 - val_loss: 0.0601 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1030 - accuracy: 0.9709 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1175 - accuracy: 0.9669 - val_loss: 0.0596 - val_accuracy: 0.9803\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1131 - accuracy: 0.9635 - val_loss: 0.0562 - val_accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1143 - accuracy: 0.9665 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1129 - accuracy: 0.9689 - val_loss: 0.0611 - val_accuracy: 0.9842\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 0.9674 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1096 - accuracy: 0.9669 - val_loss: 0.0554 - val_accuracy: 0.9803\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1190 - accuracy: 0.9699 - val_loss: 0.0558 - val_accuracy: 0.9803\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1043 - accuracy: 0.9719 - val_loss: 0.0558 - val_accuracy: 0.9842\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1059 - accuracy: 0.9719 - val_loss: 0.0543 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1065 - accuracy: 0.9739 - val_loss: 0.0528 - val_accuracy: 0.9822\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1061 - accuracy: 0.9684 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.9739 - val_loss: 0.0549 - val_accuracy: 0.9803\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1042 - accuracy: 0.9714 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1017 - accuracy: 0.9694 - val_loss: 0.0513 - val_accuracy: 0.9842\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1047 - accuracy: 0.9758 - val_loss: 0.0520 - val_accuracy: 0.9842\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9724 - val_loss: 0.0521 - val_accuracy: 0.9842\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1029 - accuracy: 0.9734 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.1025 - accuracy: 0.9748 - val_loss: 0.0525 - val_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0986 - accuracy: 0.9743 - val_loss: 0.0514 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1005 - accuracy: 0.9719 - val_loss: 0.0511 - val_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 0.0547 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1114 - accuracy: 0.9709 - val_loss: 0.0516 - val_accuracy: 0.9842\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9709 - val_loss: 0.0496 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1006 - accuracy: 0.9753 - val_loss: 0.0481 - val_accuracy: 0.9842\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0950 - accuracy: 0.9729 - val_loss: 0.0498 - val_accuracy: 0.9842\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1087 - accuracy: 0.9704 - val_loss: 0.0569 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1070 - accuracy: 0.9729 - val_loss: 0.0497 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.0493 - val_accuracy: 0.9842\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1010 - accuracy: 0.9763 - val_loss: 0.0483 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9753 - val_loss: 0.0478 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0956 - accuracy: 0.9724 - val_loss: 0.0477 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9748 - val_loss: 0.0482 - val_accuracy: 0.9862\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0986 - accuracy: 0.9704 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.9768 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.9748 - val_loss: 0.0453 - val_accuracy: 0.9842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9729 - val_loss: 0.0466 - val_accuracy: 0.9842\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9748 - val_loss: 0.0506 - val_accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0929 - accuracy: 0.9729 - val_loss: 0.0483 - val_accuracy: 0.9882\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0879 - accuracy: 0.9763 - val_loss: 0.0455 - val_accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0989 - accuracy: 0.9714 - val_loss: 0.0449 - val_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0850 - accuracy: 0.9763 - val_loss: 0.0463 - val_accuracy: 0.9862\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0959 - accuracy: 0.9719 - val_loss: 0.0477 - val_accuracy: 0.9882\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.0468 - val_accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9729 - val_loss: 0.0518 - val_accuracy: 0.9842\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 0.9739 - val_loss: 0.0442 - val_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0888 - accuracy: 0.9768 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0859 - accuracy: 0.9743 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0922 - accuracy: 0.9763 - val_loss: 0.0431 - val_accuracy: 0.9862\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0870 - accuracy: 0.9783 - val_loss: 0.0474 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.0443 - val_accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0905 - accuracy: 0.9763 - val_loss: 0.0439 - val_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0920 - accuracy: 0.9758 - val_loss: 0.0436 - val_accuracy: 0.9842\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.9793 - val_loss: 0.0440 - val_accuracy: 0.9862\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0801 - accuracy: 0.9783 - val_loss: 0.0455 - val_accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9783 - val_loss: 0.0427 - val_accuracy: 0.9862\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 32)                672       \n",
      "                                                                 \n",
      " activation_88 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_89 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,345\n",
      "Trainable params: 1,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 30ms/step - loss: 0.6887 - accuracy: 0.5220 - val_loss: 0.6724 - val_accuracy: 0.5207\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6605 - accuracy: 0.6695 - val_loss: 0.6384 - val_accuracy: 0.8876\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6289 - accuracy: 0.7292 - val_loss: 0.5997 - val_accuracy: 0.9093\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5890 - accuracy: 0.7844 - val_loss: 0.5535 - val_accuracy: 0.8876\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.5465 - accuracy: 0.8056 - val_loss: 0.4996 - val_accuracy: 0.8876\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5034 - accuracy: 0.8051 - val_loss: 0.4445 - val_accuracy: 0.9073\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.4638 - accuracy: 0.8219 - val_loss: 0.3910 - val_accuracy: 0.9132\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4009 - accuracy: 0.8698 - val_loss: 0.3266 - val_accuracy: 0.9231\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.8698 - val_loss: 0.2519 - val_accuracy: 0.9270\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 0.9038 - val_loss: 0.2034 - val_accuracy: 0.9606\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2590 - accuracy: 0.9216 - val_loss: 0.1658 - val_accuracy: 0.9724\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2323 - accuracy: 0.9314 - val_loss: 0.1433 - val_accuracy: 0.9763\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2088 - accuracy: 0.9418 - val_loss: 0.1261 - val_accuracy: 0.9724\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1781 - accuracy: 0.9492 - val_loss: 0.1164 - val_accuracy: 0.9684\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1791 - accuracy: 0.9457 - val_loss: 0.1040 - val_accuracy: 0.9744\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9546 - val_loss: 0.0996 - val_accuracy: 0.9724\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1519 - accuracy: 0.9536 - val_loss: 0.0964 - val_accuracy: 0.9763\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1448 - accuracy: 0.9615 - val_loss: 0.0945 - val_accuracy: 0.9783\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1412 - accuracy: 0.9625 - val_loss: 0.0888 - val_accuracy: 0.9763\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1377 - accuracy: 0.9615 - val_loss: 0.0862 - val_accuracy: 0.9763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1376 - accuracy: 0.9625 - val_loss: 0.0856 - val_accuracy: 0.9783\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1265 - accuracy: 0.9660 - val_loss: 0.0831 - val_accuracy: 0.9763\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1182 - accuracy: 0.9684 - val_loss: 0.0816 - val_accuracy: 0.9744\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1168 - accuracy: 0.9640 - val_loss: 0.0799 - val_accuracy: 0.9763\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9645 - val_loss: 0.0788 - val_accuracy: 0.9763\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9665 - val_loss: 0.0779 - val_accuracy: 0.9783\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1178 - accuracy: 0.9669 - val_loss: 0.0778 - val_accuracy: 0.9744\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1208 - accuracy: 0.9650 - val_loss: 0.0753 - val_accuracy: 0.9783\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1107 - accuracy: 0.9679 - val_loss: 0.0737 - val_accuracy: 0.9763\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1155 - accuracy: 0.9674 - val_loss: 0.0743 - val_accuracy: 0.9744\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1113 - accuracy: 0.9674 - val_loss: 0.0715 - val_accuracy: 0.9803\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1089 - accuracy: 0.9709 - val_loss: 0.0716 - val_accuracy: 0.9763\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1023 - accuracy: 0.9729 - val_loss: 0.0733 - val_accuracy: 0.9744\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1019 - accuracy: 0.9709 - val_loss: 0.0697 - val_accuracy: 0.9783\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.1075 - accuracy: 0.9679 - val_loss: 0.0697 - val_accuracy: 0.9783\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1114 - accuracy: 0.9665 - val_loss: 0.0700 - val_accuracy: 0.9744\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1070 - accuracy: 0.9719 - val_loss: 0.0711 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1056 - accuracy: 0.9699 - val_loss: 0.0683 - val_accuracy: 0.9744\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1003 - accuracy: 0.9724 - val_loss: 0.0683 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1027 - accuracy: 0.9699 - val_loss: 0.0671 - val_accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1000 - accuracy: 0.9719 - val_loss: 0.0677 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0939 - accuracy: 0.9724 - val_loss: 0.0682 - val_accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.1022 - accuracy: 0.9714 - val_loss: 0.0657 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 0.9734 - val_loss: 0.0669 - val_accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0934 - accuracy: 0.9734 - val_loss: 0.0645 - val_accuracy: 0.9822\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0916 - accuracy: 0.9739 - val_loss: 0.0660 - val_accuracy: 0.9763\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0989 - accuracy: 0.9729 - val_loss: 0.0645 - val_accuracy: 0.9803\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0917 - accuracy: 0.9768 - val_loss: 0.0645 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0920 - accuracy: 0.9743 - val_loss: 0.0627 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0960 - accuracy: 0.9734 - val_loss: 0.0639 - val_accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1005 - accuracy: 0.9724 - val_loss: 0.0632 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0936 - accuracy: 0.9758 - val_loss: 0.0643 - val_accuracy: 0.9822\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0952 - accuracy: 0.9773 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0925 - accuracy: 0.9743 - val_loss: 0.0630 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0912 - accuracy: 0.9729 - val_loss: 0.0638 - val_accuracy: 0.9803\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0864 - accuracy: 0.9758 - val_loss: 0.0638 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0935 - accuracy: 0.9748 - val_loss: 0.0624 - val_accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0912 - accuracy: 0.9753 - val_loss: 0.0623 - val_accuracy: 0.9803\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0896 - accuracy: 0.9753 - val_loss: 0.0622 - val_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9788 - val_loss: 0.0650 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0863 - accuracy: 0.9758 - val_loss: 0.0617 - val_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0911 - accuracy: 0.9778 - val_loss: 0.0610 - val_accuracy: 0.9783\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0876 - accuracy: 0.9773 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 0.9758 - val_loss: 0.0622 - val_accuracy: 0.9822\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0885 - accuracy: 0.9778 - val_loss: 0.0621 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0843 - accuracy: 0.9768 - val_loss: 0.0603 - val_accuracy: 0.9803\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0899 - accuracy: 0.9739 - val_loss: 0.0602 - val_accuracy: 0.9822\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9773 - val_loss: 0.0632 - val_accuracy: 0.9822\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0928 - accuracy: 0.9739 - val_loss: 0.0615 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0862 - accuracy: 0.9758 - val_loss: 0.0627 - val_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0892 - accuracy: 0.9739 - val_loss: 0.0577 - val_accuracy: 0.9783\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0916 - accuracy: 0.9768 - val_loss: 0.0577 - val_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9724 - val_loss: 0.0585 - val_accuracy: 0.9783\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0813 - accuracy: 0.9783 - val_loss: 0.0587 - val_accuracy: 0.9822\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 0.9788 - val_loss: 0.0614 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0896 - accuracy: 0.9768 - val_loss: 0.0580 - val_accuracy: 0.9822\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0873 - accuracy: 0.9788 - val_loss: 0.0574 - val_accuracy: 0.9803\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0810 - accuracy: 0.9773 - val_loss: 0.0575 - val_accuracy: 0.9803\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0911 - accuracy: 0.9748 - val_loss: 0.0589 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0782 - accuracy: 0.9793 - val_loss: 0.0570 - val_accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0827 - accuracy: 0.9778 - val_loss: 0.0583 - val_accuracy: 0.9783\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0882 - accuracy: 0.9758 - val_loss: 0.0627 - val_accuracy: 0.9783\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.9773 - val_loss: 0.0569 - val_accuracy: 0.9783\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.9783 - val_loss: 0.0569 - val_accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0788 - accuracy: 0.9798 - val_loss: 0.0565 - val_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9758 - val_loss: 0.0577 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0880 - accuracy: 0.9758 - val_loss: 0.0644 - val_accuracy: 0.9783\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0835 - accuracy: 0.9778 - val_loss: 0.0597 - val_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0843 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9803\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0850 - accuracy: 0.9778 - val_loss: 0.0553 - val_accuracy: 0.9822\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.0600 - val_accuracy: 0.9822\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0789 - accuracy: 0.9798 - val_loss: 0.0601 - val_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0875 - accuracy: 0.9763 - val_loss: 0.0555 - val_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0810 - accuracy: 0.9803 - val_loss: 0.0547 - val_accuracy: 0.9822\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0757 - accuracy: 0.9788 - val_loss: 0.0591 - val_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0816 - accuracy: 0.9793 - val_loss: 0.0540 - val_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0734 - accuracy: 0.9793 - val_loss: 0.0557 - val_accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0820 - accuracy: 0.9778 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0819 - accuracy: 0.9778 - val_loss: 0.0533 - val_accuracy: 0.9842\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9788 - val_loss: 0.0535 - val_accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "# اثر تعداد نورون های وسط\n",
    "n_mids = [i for i in range(1,21)]\n",
    "acc = []\n",
    "for n_mid in n_mids:\n",
    "    model, history = training(activation='relu',has_dropout=True )\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    acc.append(test_score[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x20dfdc74b50>]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_mids,acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}